{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[],"gpuType":"T4"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"},"accelerator":"GPU"},"cells":[{"cell_type":"markdown","source":["# Import Libraries"],"metadata":{"id":"CE-FGl5OJU6r"}},{"cell_type":"code","execution_count":1,"metadata":{"id":"vXzzROv3E0-a","executionInfo":{"status":"ok","timestamp":1709562163782,"user_tz":-60,"elapsed":4443,"user":{"displayName":"abcr 5914","userId":"14460359779719086070"}}},"outputs":[],"source":["import numpy as np\n","import pandas as pd\n","import re\n","\n","from sklearn.preprocessing import LabelEncoder\n","\n","from keras.applications.vgg16 import VGG16, preprocess_input\n","\n","from tensorflow.keras.preprocessing import image\n","\n"]},{"cell_type":"markdown","source":["# Checking GPU Information using NVIDIA System Management Interface (nvidia-smi)\n","\n","This code snippet utilizes the NVIDIA System Management Interface (nvidia-smi) to provide information about the available GPU(s) in the Colab environment.\n","The command '!nvidia-smi' is executed to display details such as GPU model, memory usage, and temperature.\n","This information is valuable when working on tasks that benefit from GPU acceleration, such as deep learning.\n","\n","Note: Colab provides access to GPUs, but the specific GPU model and capabilities may vary.\n"],"metadata":{"id":"9IiQBdFqKA7B"}},{"cell_type":"code","source":["!nvidia-smi"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"3QguxFcmFC7l","outputId":"57158809-748d-47a6-dda4-8064b67d514f","executionInfo":{"status":"ok","timestamp":1709562163782,"user_tz":-60,"elapsed":10,"user":{"displayName":"abcr 5914","userId":"14460359779719086070"}}},"execution_count":2,"outputs":[{"output_type":"stream","name":"stdout","text":["/bin/bash: line 1: nvidia-smi: command not found\n"]}]},{"cell_type":"markdown","source":["# Loading Data from Kaggle in Colab\n","\n","This code snippet demonstrates the process of loading data from Kaggle into a Colab notebook environment.\n","It utilizes the 'files' module from the 'google.colab' library to upload the Kaggle API key (kaggle.json).\n","Additionally, it installs the 'kaggle' Python package, sets up the Kaggle API key, and downloads a specific dataset.\n","In this example, the dataset 'visuelle2' is downloaded and extracted using the Kaggle command line interface.\n","\n","Instructions:\n","1. Upload your Kaggle API key (kaggle.json) using the file upload widget.\n","2. Install the 'kaggle' Python package.\n","3. Set up the Kaggle API key, move it to the appropriate directory, and adjust permissions.\n","4. Download and unzip the desired Kaggle dataset using the 'kaggle datasets download' command.\n","\n","Note: Make sure to replace 'dqhdqmcttdqx/visuelle2' with the actual Kaggle dataset URL you want to download.\n"],"metadata":{"id":"7c8RpqV1KI6Z"}},{"cell_type":"code","source":["#Load data frpm kaggle\n","from google.colab import files\n","files.upload()\n","\n","%pip install -q kaggle\n","!rm -r ~/.kaggle\n","!mkdir ~/.kaggle\n","!mv ./kaggle.json ~/.kaggle/\n","!chmod 600 ~/.kaggle/kaggle.json\n","#!kaggle datasets list\n","!kaggle datasets download dqhdqmcttdqx/visuelle2 --unzip"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":142},"id":"uhs-oXSqFFvd","outputId":"12b2a439-f654-4c6a-c912-4e2039a7ed3a","executionInfo":{"status":"ok","timestamp":1709522379693,"user_tz":-60,"elapsed":56427,"user":{"displayName":"abcr 5914","userId":"14460359779719086070"}}},"execution_count":null,"outputs":[{"output_type":"display_data","data":{"text/plain":["<IPython.core.display.HTML object>"],"text/html":["\n","     <input type=\"file\" id=\"files-d4a22411-5d83-4458-a776-12563229505b\" name=\"files[]\" multiple disabled\n","        style=\"border:none\" />\n","     <output id=\"result-d4a22411-5d83-4458-a776-12563229505b\">\n","      Upload widget is only available when the cell has been executed in the\n","      current browser session. Please rerun this cell to enable.\n","      </output>\n","      <script>// Copyright 2017 Google LLC\n","//\n","// Licensed under the Apache License, Version 2.0 (the \"License\");\n","// you may not use this file except in compliance with the License.\n","// You may obtain a copy of the License at\n","//\n","//      http://www.apache.org/licenses/LICENSE-2.0\n","//\n","// Unless required by applicable law or agreed to in writing, software\n","// distributed under the License is distributed on an \"AS IS\" BASIS,\n","// WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n","// See the License for the specific language governing permissions and\n","// limitations under the License.\n","\n","/**\n"," * @fileoverview Helpers for google.colab Python module.\n"," */\n","(function(scope) {\n","function span(text, styleAttributes = {}) {\n","  const element = document.createElement('span');\n","  element.textContent = text;\n","  for (const key of Object.keys(styleAttributes)) {\n","    element.style[key] = styleAttributes[key];\n","  }\n","  return element;\n","}\n","\n","// Max number of bytes which will be uploaded at a time.\n","const MAX_PAYLOAD_SIZE = 100 * 1024;\n","\n","function _uploadFiles(inputId, outputId) {\n","  const steps = uploadFilesStep(inputId, outputId);\n","  const outputElement = document.getElementById(outputId);\n","  // Cache steps on the outputElement to make it available for the next call\n","  // to uploadFilesContinue from Python.\n","  outputElement.steps = steps;\n","\n","  return _uploadFilesContinue(outputId);\n","}\n","\n","// This is roughly an async generator (not supported in the browser yet),\n","// where there are multiple asynchronous steps and the Python side is going\n","// to poll for completion of each step.\n","// This uses a Promise to block the python side on completion of each step,\n","// then passes the result of the previous step as the input to the next step.\n","function _uploadFilesContinue(outputId) {\n","  const outputElement = document.getElementById(outputId);\n","  const steps = outputElement.steps;\n","\n","  const next = steps.next(outputElement.lastPromiseValue);\n","  return Promise.resolve(next.value.promise).then((value) => {\n","    // Cache the last promise value to make it available to the next\n","    // step of the generator.\n","    outputElement.lastPromiseValue = value;\n","    return next.value.response;\n","  });\n","}\n","\n","/**\n"," * Generator function which is called between each async step of the upload\n"," * process.\n"," * @param {string} inputId Element ID of the input file picker element.\n"," * @param {string} outputId Element ID of the output display.\n"," * @return {!Iterable<!Object>} Iterable of next steps.\n"," */\n","function* uploadFilesStep(inputId, outputId) {\n","  const inputElement = document.getElementById(inputId);\n","  inputElement.disabled = false;\n","\n","  const outputElement = document.getElementById(outputId);\n","  outputElement.innerHTML = '';\n","\n","  const pickedPromise = new Promise((resolve) => {\n","    inputElement.addEventListener('change', (e) => {\n","      resolve(e.target.files);\n","    });\n","  });\n","\n","  const cancel = document.createElement('button');\n","  inputElement.parentElement.appendChild(cancel);\n","  cancel.textContent = 'Cancel upload';\n","  const cancelPromise = new Promise((resolve) => {\n","    cancel.onclick = () => {\n","      resolve(null);\n","    };\n","  });\n","\n","  // Wait for the user to pick the files.\n","  const files = yield {\n","    promise: Promise.race([pickedPromise, cancelPromise]),\n","    response: {\n","      action: 'starting',\n","    }\n","  };\n","\n","  cancel.remove();\n","\n","  // Disable the input element since further picks are not allowed.\n","  inputElement.disabled = true;\n","\n","  if (!files) {\n","    return {\n","      response: {\n","        action: 'complete',\n","      }\n","    };\n","  }\n","\n","  for (const file of files) {\n","    const li = document.createElement('li');\n","    li.append(span(file.name, {fontWeight: 'bold'}));\n","    li.append(span(\n","        `(${file.type || 'n/a'}) - ${file.size} bytes, ` +\n","        `last modified: ${\n","            file.lastModifiedDate ? file.lastModifiedDate.toLocaleDateString() :\n","                                    'n/a'} - `));\n","    const percent = span('0% done');\n","    li.appendChild(percent);\n","\n","    outputElement.appendChild(li);\n","\n","    const fileDataPromise = new Promise((resolve) => {\n","      const reader = new FileReader();\n","      reader.onload = (e) => {\n","        resolve(e.target.result);\n","      };\n","      reader.readAsArrayBuffer(file);\n","    });\n","    // Wait for the data to be ready.\n","    let fileData = yield {\n","      promise: fileDataPromise,\n","      response: {\n","        action: 'continue',\n","      }\n","    };\n","\n","    // Use a chunked sending to avoid message size limits. See b/62115660.\n","    let position = 0;\n","    do {\n","      const length = Math.min(fileData.byteLength - position, MAX_PAYLOAD_SIZE);\n","      const chunk = new Uint8Array(fileData, position, length);\n","      position += length;\n","\n","      const base64 = btoa(String.fromCharCode.apply(null, chunk));\n","      yield {\n","        response: {\n","          action: 'append',\n","          file: file.name,\n","          data: base64,\n","        },\n","      };\n","\n","      let percentDone = fileData.byteLength === 0 ?\n","          100 :\n","          Math.round((position / fileData.byteLength) * 100);\n","      percent.textContent = `${percentDone}% done`;\n","\n","    } while (position < fileData.byteLength);\n","  }\n","\n","  // All done.\n","  yield {\n","    response: {\n","      action: 'complete',\n","    }\n","  };\n","}\n","\n","scope.google = scope.google || {};\n","scope.google.colab = scope.google.colab || {};\n","scope.google.colab._files = {\n","  _uploadFiles,\n","  _uploadFilesContinue,\n","};\n","})(self);\n","</script> "]},"metadata":{}},{"output_type":"stream","name":"stdout","text":["Saving kaggle.json to kaggle.json\n","rm: cannot remove '/root/.kaggle': No such file or directory\n","Downloading visuelle2.zip to /content\n"," 99% 2.07G/2.09G [00:21<00:00, 87.7MB/s]\n","100% 2.09G/2.09G [00:22<00:00, 102MB/s] \n"]}]},{"cell_type":"markdown","source":["# Loading and Displaying Data from CSV File\n","\n","This code snippet reads a CSV file named 'sales.csv' from the specified path (\"/content/visuelle2/\") using Pandas.\n","The loaded data is stored in a Pandas DataFrame named 'data'.\n","Subsequently, the 'head()' function is used to display the first few rows of the DataFrame.\n","\n","Instructions:\n","1. Ensure that the CSV file 'sales.csv' is located in the correct directory (\"/content/visuelle2/\").\n","2. Run this code to load the data into the 'data' DataFrame and print the first few rows.\n","\n","\n","Note: Adjust the file path if the CSV file is located in a different directory.\n"],"metadata":{"id":"Vs8ay1DTKNvM"}},{"cell_type":"code","source":["data = pd.read_csv(\"/content/visuelle2/sales.csv\")\n","print(data.head())"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"21f3wV_QFY3a","outputId":"f194c127-7e12-4fa5-a069-64a6df23a72e","executionInfo":{"status":"ok","timestamp":1709524968523,"user_tz":-60,"elapsed":569,"user":{"displayName":"abcr 5914","userId":"14460359779719086070"}}},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["   Unnamed: 0  external_code  retail season     category   color  \\\n","0           0              5      36   SS17  long sleeve    grey   \n","1           1              2      51   SS17  long sleeve  violet   \n","2           2              5      10   SS17  long sleeve    grey   \n","3           3              9      41   SS17     culottes  yellow   \n","4           4              5      13   SS17  long sleeve    grey   \n","\n","       image_path       fabric release_date  restock  ...    2    3    4    5  \\\n","0  PE17/00005.png      acrylic   2016-11-28       22  ...  1.0  1.0  2.0  1.0   \n","1  PE17/00002.png      acrylic   2016-11-28       17  ...  1.0  0.0  0.0  2.0   \n","2  PE17/00005.png      acrylic   2016-11-28       15  ...  1.0  0.0  1.0  1.0   \n","3  PE17/00009.png  scuba crepe   2016-11-28       32  ...  1.0  1.0  0.0  0.0   \n","4  PE17/00005.png      acrylic   2016-11-28       26  ...  4.0  0.0  3.0  0.0   \n","\n","     6    7    8    9   10   11  \n","0  0.0  0.0  2.0  0.0  0.0  0.0  \n","1  0.0  0.0  0.0  1.0  1.0  0.0  \n","2  1.0  1.0  1.0  0.0  0.0  1.0  \n","3  0.0  1.0  0.0  1.0  0.0  0.0  \n","4  2.0  1.0  0.0  0.0  0.0  0.0  \n","\n","[5 rows x 22 columns]\n"]}]},{"cell_type":"code","source":["'''\n","data = pd.read_csv(\"/content/visuelle2/stfore_train.csv\")\n","print(data.head())\n","print(data.shape)\n","'''"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":35},"id":"dZC14zM-Y5aY","executionInfo":{"status":"ok","timestamp":1709524951122,"user_tz":-60,"elapsed":279,"user":{"displayName":"abcr 5914","userId":"14460359779719086070"}},"outputId":"75f513df-d011-42ce-bfdd-357325ed022f"},"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["'\\ndata = pd.read_csv(\"/content/visuelle2/stfore_train.csv\")\\nprint(data.head())\\nprint(data.shape)\\n'"],"application/vnd.google.colaboratory.intrinsic+json":{"type":"string"}},"metadata":{},"execution_count":8}]},{"cell_type":"markdown","source":["# Features encoding\n","\n","This code snippet focuses on encoding categorical variables and images within a Pandas DataFrame. The categorical variables, namely \"category,\" \"color,\" and \"fabric,\" are encoded using the LabelEncoder from scikit-learn. The resulting encoded values are stored in new columns named \"category_encoded,\" \"color_encoded,\" and \"fabric_encoded.\"\n","\n","Furthermore, images specified in the \"image_path\" column are processed using a pre-trained VGG16 model to extract features. The encoding process is designed for efficiency by storing the encoded image features in a dictionary (\"image_features_dict\") for future retrieval. The 'encode_image' function handles the loading, preprocessing, and feature extraction for each image path. The resulting image features are stored in the \"image_features\" column of the DataFrame.\n","\n","To use this code:\n","1. Ensure that your DataFrame, named 'data,' contains the necessary columns: \"category,\" \"color,\" \"fabric,\" and \"image_path.\"\n","2. Execute the code to perform the encoding of categorical variables and images.\n","3. The encoded values for categorical variables and image features are stored in respective columns in the DataFrame.\n","\n","Note: Adjust the paths and column names accordingly if your DataFrame structure is different."],"metadata":{"id":"MuxA2fvqK85q"}},{"cell_type":"code","source":["\n","# Encode categorical variables using LabelEncoder\n","le = LabelEncoder()\n","data[\"category_encoded\"] = le.fit_transform(data[\"category\"])\n","data[\"color_encoded\"] = le.fit_transform(data[\"color\"])\n","data[\"fabric_encoded\"] = le.fit_transform(data[\"fabric\"])\n","\n","# Encode images using a pre-trained image model (optimized for multiple occurrences)\n","image_features_dict = {}  # Store features for efficient retrieval\n","\n","def encode_image(image_path):\n","    if image_path not in image_features_dict:\n","        # Load and preprocess the image (only if not already encoded)\n","        path = '//content/visuelle2/images/' + image_path\n","        img = image.load_img(path, target_size=(224, 224))\n","        x = image.img_to_array(img)\n","        x = np.expand_dims(x, axis=0)\n","        x = preprocess_input(x)\n","\n","        # Extract features using VGG16\n","        model = VGG16(weights=\"imagenet\", include_top=False)\n","        #model = MobileNet(weights=\"imagenet\", include_top=False)\n","        features = model.predict(x, verbose=0).flatten()  # Flatten directly\n","\n","        # Store features for future retrieval\n","        image_features_dict[image_path] = features\n","        if int(len(image_features_dict))%1000 == 0:\n","          print (\"step: \", len(image_features_dict))\n","\n","    return image_features_dict[image_path]  # Retrieve stored features\n","\n","# Apply encoding efficiently using the dictionary\n","data[\"image_features\"] = data[\"image_path\"].apply(encode_image)\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":321},"id":"5awS_5_QFhFg","outputId":"3afbde49-2128-48f1-cd8c-6d28482bd084","executionInfo":{"status":"error","timestamp":1709525145630,"user_tz":-60,"elapsed":174255,"user":{"displayName":"abcr 5914","userId":"14460359779719086070"}}},"execution_count":null,"outputs":[{"output_type":"error","ename":"KeyboardInterrupt","evalue":"","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)","\u001b[0;32m<ipython-input-10-31cbd3e7d6ab>\u001b[0m in \u001b[0;36m<cell line: 32>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     30\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     31\u001b[0m \u001b[0;31m# Apply encoding efficiently using the dictionary\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 32\u001b[0;31m \u001b[0mdata\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"image_features\"\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"image_path\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mapply\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mencode_image\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/pandas/core/series.py\u001b[0m in \u001b[0;36mapply\u001b[0;34m(self, func, convert_dtype, args, **kwargs)\u001b[0m\n\u001b[1;32m   4769\u001b[0m         \u001b[0mdtype\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mfloat64\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   4770\u001b[0m         \"\"\"\n\u001b[0;32m-> 4771\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mSeriesApply\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mconvert_dtype\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mapply\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   4772\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   4773\u001b[0m     def _reduce(\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/pandas/core/apply.py\u001b[0m in \u001b[0;36mapply\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1121\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1122\u001b[0m         \u001b[0;31m# self.f is Callable\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1123\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mapply_standard\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1124\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1125\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0magg\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/pandas/core/apply.py\u001b[0m in \u001b[0;36mapply_standard\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1172\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1173\u001b[0m                 \u001b[0mvalues\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mobj\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mastype\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mobject\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_values\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1174\u001b[0;31m                 mapped = lib.map_infer(\n\u001b[0m\u001b[1;32m   1175\u001b[0m                     \u001b[0mvalues\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1176\u001b[0m                     \u001b[0mf\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/pandas/_libs/lib.pyx\u001b[0m in \u001b[0;36mpandas._libs.lib.map_infer\u001b[0;34m()\u001b[0m\n","\u001b[0;32m<ipython-input-10-31cbd3e7d6ab>\u001b[0m in \u001b[0;36mencode_image\u001b[0;34m(image_path)\u001b[0m\n\u001b[1;32m     18\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     19\u001b[0m         \u001b[0;31m# Extract features using VGG16\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 20\u001b[0;31m         \u001b[0mmodel\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mVGG16\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mweights\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"imagenet\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minclude_top\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     21\u001b[0m         \u001b[0;31m#model = MobileNet(weights=\"imagenet\", include_top=False)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     22\u001b[0m         \u001b[0mfeatures\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mverbose\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mflatten\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# Flatten directly\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/keras/src/applications/vgg16.py\u001b[0m in \u001b[0;36mVGG16\u001b[0;34m(include_top, weights, input_tensor, input_shape, pooling, classes, classifier_activation)\u001b[0m\n\u001b[1;32m    246\u001b[0m                 \u001b[0mfile_hash\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"6d6bbae143d832006294945121d1f1fc\"\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    247\u001b[0m             )\n\u001b[0;32m--> 248\u001b[0;31m         \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload_weights\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mweights_path\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    249\u001b[0m     \u001b[0;32melif\u001b[0m \u001b[0mweights\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    250\u001b[0m         \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload_weights\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mweights\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/keras/src/utils/traceback_utils.py\u001b[0m in \u001b[0;36merror_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     63\u001b[0m         \u001b[0mfiltered_tb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     64\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 65\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     66\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     67\u001b[0m             \u001b[0mfiltered_tb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_process_traceback_frames\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__traceback__\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/keras/src/engine/training.py\u001b[0m in \u001b[0;36mload_weights\u001b[0;34m(self, filepath, skip_mismatch, by_name, options)\u001b[0m\n\u001b[1;32m   3233\u001b[0m                 \u001b[0moptions\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mloading\u001b[0m \u001b[0mweights\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0monly\u001b[0m \u001b[0mvalid\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0ma\u001b[0m \u001b[0mSavedModel\u001b[0m \u001b[0mfile\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3234\u001b[0m         \"\"\"\n\u001b[0;32m-> 3235\u001b[0;31m         return saving_api.load_weights(\n\u001b[0m\u001b[1;32m   3236\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3237\u001b[0m             \u001b[0mfilepath\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mfilepath\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/keras/src/saving/saving_api.py\u001b[0m in \u001b[0;36mload_weights\u001b[0;34m(model, filepath, skip_mismatch, **kwargs)\u001b[0m\n\u001b[1;32m    303\u001b[0m         )\n\u001b[1;32m    304\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 305\u001b[0;31m         return legacy_sm_saving_lib.load_weights(\n\u001b[0m\u001b[1;32m    306\u001b[0m             \u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfilepath\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mskip_mismatch\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mskip_mismatch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    307\u001b[0m         )\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/keras/src/saving/legacy/save.py\u001b[0m in \u001b[0;36mload_weights\u001b[0;34m(model, filepath, by_name, skip_mismatch, options)\u001b[0m\n\u001b[1;32m    492\u001b[0m                 )\n\u001b[1;32m    493\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 494\u001b[0;31m                 \u001b[0mhdf5_format\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload_weights_from_hdf5_group\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    495\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    496\u001b[0m     \u001b[0;31m# Perform any layer defined finalization of the layer state.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/keras/src/saving/legacy/hdf5_format.py\u001b[0m in \u001b[0;36mload_weights_from_hdf5_group\u001b[0;34m(f, model)\u001b[0m\n\u001b[1;32m    858\u001b[0m             )\n\u001b[1;32m    859\u001b[0m         \u001b[0mweight_value_tuples\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0mzip\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msymbolic_weights\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mweight_values\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 860\u001b[0;31m     \u001b[0mbackend\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbatch_set_value\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mweight_value_tuples\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    861\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    862\u001b[0m     \u001b[0;31m# Perform any layer defined finalization of the layer state.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/tensorflow/python/util/traceback_utils.py\u001b[0m in \u001b[0;36merror_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    148\u001b[0m     \u001b[0mfiltered_tb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    149\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 150\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    151\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    152\u001b[0m       \u001b[0mfiltered_tb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_process_traceback_frames\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__traceback__\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/tensorflow/python/util/dispatch.py\u001b[0m in \u001b[0;36mop_dispatch_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m   1258\u001b[0m       \u001b[0;31m# Fallback dispatch system (dispatch v1):\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1259\u001b[0m       \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1260\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mdispatch_target\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1261\u001b[0m       \u001b[0;32mexcept\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mTypeError\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mValueError\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1262\u001b[0m         \u001b[0;31m# Note: convert_to_eager_tensor currently raises a ValueError, not a\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/keras/src/backend.py\u001b[0m in \u001b[0;36mbatch_set_value\u001b[0;34m(tuples)\u001b[0m\n\u001b[1;32m   4309\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalue\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mtuples\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   4310\u001b[0m             \u001b[0mvalue\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0masarray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvalue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdtype_numpy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 4311\u001b[0;31m             \u001b[0m_assign_value_to_variable\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   4312\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   4313\u001b[0m         \u001b[0;32mwith\u001b[0m \u001b[0mget_graph\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mas_default\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/keras/src/backend.py\u001b[0m in \u001b[0;36m_assign_value_to_variable\u001b[0;34m(variable, value)\u001b[0m\n\u001b[1;32m   4357\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   4358\u001b[0m         \u001b[0;31m# For the normal tf.Variable assign\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 4359\u001b[0;31m         \u001b[0mvariable\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0massign\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvalue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   4360\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   4361\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/tensorflow/python/ops/weak_tensor_ops.py\u001b[0m in \u001b[0;36mwrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    140\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0mwrapper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    141\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mops\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mis_auto_dtype_conversion_enabled\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 142\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mop\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    143\u001b[0m     \u001b[0mbound_arguments\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msignature\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbind\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    144\u001b[0m     \u001b[0mbound_arguments\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mapply_defaults\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/tensorflow/python/ops/resource_variable_ops.py\u001b[0m in \u001b[0;36massign\u001b[0;34m(self, value, use_locking, name, read_value)\u001b[0m\n\u001b[1;32m   1039\u001b[0m     \u001b[0;32mwith\u001b[0m \u001b[0m_handle_graph\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhandle\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1040\u001b[0m       \u001b[0mvalue_tensor\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mops\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconvert_to_tensor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvalue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdtype\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1041\u001b[0;31m       \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_shape\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mis_compatible_with\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvalue_tensor\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1042\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mname\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1043\u001b[0m           \u001b[0mtensor_name\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m\"\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/tensorflow/python/framework/ops.py\u001b[0m in \u001b[0;36mshape\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    496\u001b[0m         \u001b[0;31m# `_tensor_shape` is declared and defined in the definition of\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    497\u001b[0m         \u001b[0;31m# `EagerTensor`, in C.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 498\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_tensor_shape\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtensor_shape\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTensorShape\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_shape_tuple\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    499\u001b[0m       \u001b[0;32mexcept\u001b[0m \u001b[0mcore\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_NotOkStatusException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    500\u001b[0m         \u001b[0;32mraise\u001b[0m \u001b[0mcore\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_status_to_exception\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/tensorflow/python/framework/tensor_shape.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, dims)\u001b[0m\n\u001b[1;32m    827\u001b[0m       \u001b[0mTypeError\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mIf\u001b[0m \u001b[0mdims\u001b[0m \u001b[0mcannot\u001b[0m \u001b[0mbe\u001b[0m \u001b[0mconverted\u001b[0m \u001b[0mto\u001b[0m \u001b[0ma\u001b[0m \u001b[0mlist\u001b[0m \u001b[0mof\u001b[0m \u001b[0mdimensions\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    828\u001b[0m     \"\"\"\n\u001b[0;32m--> 829\u001b[0;31m     \u001b[0;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdims\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mtuple\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlist\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m  \u001b[0;31m# Most common case.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    830\u001b[0m       \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_dims\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtuple\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mas_dimension\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0md\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalue\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0md\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mdims\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    831\u001b[0m     \u001b[0;32melif\u001b[0m \u001b[0mdims\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mKeyboardInterrupt\u001b[0m: "]}]},{"cell_type":"markdown","source":["# Print dataframe head"],"metadata":{"id":"QE3aARNxLgmf"}},{"cell_type":"code","source":["data.head()"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":322},"id":"IqGA6AHjS3Po","outputId":"c1b5e22a-ded4-4079-dcfe-e96ca38beb97","executionInfo":{"status":"ok","timestamp":1709524810744,"user_tz":-60,"elapsed":234,"user":{"displayName":"abcr 5914","userId":"14460359779719086070"}}},"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["   external_code  retail season     category   color      image_path  \\\n","0              5      36   SS17  long sleeve    grey  PE17/00005.png   \n","1              2      51   SS17  long sleeve  violet  PE17/00002.png   \n","2              5      10   SS17  long sleeve    grey  PE17/00005.png   \n","3              9      41   SS17     culottes  yellow  PE17/00009.png   \n","4              5      13   SS17  long sleeve    grey  PE17/00005.png   \n","\n","        fabric release_date   restock         0  ...         5         6  \\\n","0      acrylic   2016-11-28  0.415094  0.018868  ...  0.018868  0.000000   \n","1      acrylic   2016-11-28  0.320755  0.018868  ...  0.037736  0.000000   \n","2      acrylic   2016-11-28  0.283019  0.018868  ...  0.018868  0.018868   \n","3  scuba crepe   2016-11-28  0.603774  0.018868  ...  0.000000  0.000000   \n","4      acrylic   2016-11-28  0.490566  0.018868  ...  0.000000  0.037736   \n","\n","          7         8         9        10        11  category_encoded  \\\n","0  0.000000  0.037736  0.000000  0.000000  0.000000                11   \n","1  0.000000  0.000000  0.018868  0.018868  0.000000                11   \n","2  0.018868  0.018868  0.000000  0.000000  0.018868                11   \n","3  0.018868  0.000000  0.018868  0.000000  0.000000                 1   \n","4  0.018868  0.000000  0.000000  0.000000  0.000000                11   \n","\n","   color_encoded  fabric_encoded  \n","0              4               0  \n","1              7               0  \n","2              4               0  \n","3              9              49  \n","4              4               0  \n","\n","[5 rows x 24 columns]"],"text/html":["\n","  <div id=\"df-e4c0978c-368b-4bde-b87d-cc56b16b6a6c\" class=\"colab-df-container\">\n","    <div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>external_code</th>\n","      <th>retail</th>\n","      <th>season</th>\n","      <th>category</th>\n","      <th>color</th>\n","      <th>image_path</th>\n","      <th>fabric</th>\n","      <th>release_date</th>\n","      <th>restock</th>\n","      <th>0</th>\n","      <th>...</th>\n","      <th>5</th>\n","      <th>6</th>\n","      <th>7</th>\n","      <th>8</th>\n","      <th>9</th>\n","      <th>10</th>\n","      <th>11</th>\n","      <th>category_encoded</th>\n","      <th>color_encoded</th>\n","      <th>fabric_encoded</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>0</th>\n","      <td>5</td>\n","      <td>36</td>\n","      <td>SS17</td>\n","      <td>long sleeve</td>\n","      <td>grey</td>\n","      <td>PE17/00005.png</td>\n","      <td>acrylic</td>\n","      <td>2016-11-28</td>\n","      <td>0.415094</td>\n","      <td>0.018868</td>\n","      <td>...</td>\n","      <td>0.018868</td>\n","      <td>0.000000</td>\n","      <td>0.000000</td>\n","      <td>0.037736</td>\n","      <td>0.000000</td>\n","      <td>0.000000</td>\n","      <td>0.000000</td>\n","      <td>11</td>\n","      <td>4</td>\n","      <td>0</td>\n","    </tr>\n","    <tr>\n","      <th>1</th>\n","      <td>2</td>\n","      <td>51</td>\n","      <td>SS17</td>\n","      <td>long sleeve</td>\n","      <td>violet</td>\n","      <td>PE17/00002.png</td>\n","      <td>acrylic</td>\n","      <td>2016-11-28</td>\n","      <td>0.320755</td>\n","      <td>0.018868</td>\n","      <td>...</td>\n","      <td>0.037736</td>\n","      <td>0.000000</td>\n","      <td>0.000000</td>\n","      <td>0.000000</td>\n","      <td>0.018868</td>\n","      <td>0.018868</td>\n","      <td>0.000000</td>\n","      <td>11</td>\n","      <td>7</td>\n","      <td>0</td>\n","    </tr>\n","    <tr>\n","      <th>2</th>\n","      <td>5</td>\n","      <td>10</td>\n","      <td>SS17</td>\n","      <td>long sleeve</td>\n","      <td>grey</td>\n","      <td>PE17/00005.png</td>\n","      <td>acrylic</td>\n","      <td>2016-11-28</td>\n","      <td>0.283019</td>\n","      <td>0.018868</td>\n","      <td>...</td>\n","      <td>0.018868</td>\n","      <td>0.018868</td>\n","      <td>0.018868</td>\n","      <td>0.018868</td>\n","      <td>0.000000</td>\n","      <td>0.000000</td>\n","      <td>0.018868</td>\n","      <td>11</td>\n","      <td>4</td>\n","      <td>0</td>\n","    </tr>\n","    <tr>\n","      <th>3</th>\n","      <td>9</td>\n","      <td>41</td>\n","      <td>SS17</td>\n","      <td>culottes</td>\n","      <td>yellow</td>\n","      <td>PE17/00009.png</td>\n","      <td>scuba crepe</td>\n","      <td>2016-11-28</td>\n","      <td>0.603774</td>\n","      <td>0.018868</td>\n","      <td>...</td>\n","      <td>0.000000</td>\n","      <td>0.000000</td>\n","      <td>0.018868</td>\n","      <td>0.000000</td>\n","      <td>0.018868</td>\n","      <td>0.000000</td>\n","      <td>0.000000</td>\n","      <td>1</td>\n","      <td>9</td>\n","      <td>49</td>\n","    </tr>\n","    <tr>\n","      <th>4</th>\n","      <td>5</td>\n","      <td>13</td>\n","      <td>SS17</td>\n","      <td>long sleeve</td>\n","      <td>grey</td>\n","      <td>PE17/00005.png</td>\n","      <td>acrylic</td>\n","      <td>2016-11-28</td>\n","      <td>0.490566</td>\n","      <td>0.018868</td>\n","      <td>...</td>\n","      <td>0.000000</td>\n","      <td>0.037736</td>\n","      <td>0.018868</td>\n","      <td>0.000000</td>\n","      <td>0.000000</td>\n","      <td>0.000000</td>\n","      <td>0.000000</td>\n","      <td>11</td>\n","      <td>4</td>\n","      <td>0</td>\n","    </tr>\n","  </tbody>\n","</table>\n","<p>5 rows × 24 columns</p>\n","</div>\n","    <div class=\"colab-df-buttons\">\n","\n","  <div class=\"colab-df-container\">\n","    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-e4c0978c-368b-4bde-b87d-cc56b16b6a6c')\"\n","            title=\"Convert this dataframe to an interactive table.\"\n","            style=\"display:none;\">\n","\n","  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n","    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n","  </svg>\n","    </button>\n","\n","  <style>\n","    .colab-df-container {\n","      display:flex;\n","      gap: 12px;\n","    }\n","\n","    .colab-df-convert {\n","      background-color: #E8F0FE;\n","      border: none;\n","      border-radius: 50%;\n","      cursor: pointer;\n","      display: none;\n","      fill: #1967D2;\n","      height: 32px;\n","      padding: 0 0 0 0;\n","      width: 32px;\n","    }\n","\n","    .colab-df-convert:hover {\n","      background-color: #E2EBFA;\n","      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n","      fill: #174EA6;\n","    }\n","\n","    .colab-df-buttons div {\n","      margin-bottom: 4px;\n","    }\n","\n","    [theme=dark] .colab-df-convert {\n","      background-color: #3B4455;\n","      fill: #D2E3FC;\n","    }\n","\n","    [theme=dark] .colab-df-convert:hover {\n","      background-color: #434B5C;\n","      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n","      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n","      fill: #FFFFFF;\n","    }\n","  </style>\n","\n","    <script>\n","      const buttonEl =\n","        document.querySelector('#df-e4c0978c-368b-4bde-b87d-cc56b16b6a6c button.colab-df-convert');\n","      buttonEl.style.display =\n","        google.colab.kernel.accessAllowed ? 'block' : 'none';\n","\n","      async function convertToInteractive(key) {\n","        const element = document.querySelector('#df-e4c0978c-368b-4bde-b87d-cc56b16b6a6c');\n","        const dataTable =\n","          await google.colab.kernel.invokeFunction('convertToInteractive',\n","                                                    [key], {});\n","        if (!dataTable) return;\n","\n","        const docLinkHtml = 'Like what you see? Visit the ' +\n","          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n","          + ' to learn more about interactive tables.';\n","        element.innerHTML = '';\n","        dataTable['output_type'] = 'display_data';\n","        await google.colab.output.renderOutput(dataTable, element);\n","        const docLink = document.createElement('div');\n","        docLink.innerHTML = docLinkHtml;\n","        element.appendChild(docLink);\n","      }\n","    </script>\n","  </div>\n","\n","\n","<div id=\"df-417b2d44-d7ee-43ea-8d7c-20b771125f50\">\n","  <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-417b2d44-d7ee-43ea-8d7c-20b771125f50')\"\n","            title=\"Suggest charts\"\n","            style=\"display:none;\">\n","\n","<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n","     width=\"24px\">\n","    <g>\n","        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n","    </g>\n","</svg>\n","  </button>\n","\n","<style>\n","  .colab-df-quickchart {\n","      --bg-color: #E8F0FE;\n","      --fill-color: #1967D2;\n","      --hover-bg-color: #E2EBFA;\n","      --hover-fill-color: #174EA6;\n","      --disabled-fill-color: #AAA;\n","      --disabled-bg-color: #DDD;\n","  }\n","\n","  [theme=dark] .colab-df-quickchart {\n","      --bg-color: #3B4455;\n","      --fill-color: #D2E3FC;\n","      --hover-bg-color: #434B5C;\n","      --hover-fill-color: #FFFFFF;\n","      --disabled-bg-color: #3B4455;\n","      --disabled-fill-color: #666;\n","  }\n","\n","  .colab-df-quickchart {\n","    background-color: var(--bg-color);\n","    border: none;\n","    border-radius: 50%;\n","    cursor: pointer;\n","    display: none;\n","    fill: var(--fill-color);\n","    height: 32px;\n","    padding: 0;\n","    width: 32px;\n","  }\n","\n","  .colab-df-quickchart:hover {\n","    background-color: var(--hover-bg-color);\n","    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n","    fill: var(--button-hover-fill-color);\n","  }\n","\n","  .colab-df-quickchart-complete:disabled,\n","  .colab-df-quickchart-complete:disabled:hover {\n","    background-color: var(--disabled-bg-color);\n","    fill: var(--disabled-fill-color);\n","    box-shadow: none;\n","  }\n","\n","  .colab-df-spinner {\n","    border: 2px solid var(--fill-color);\n","    border-color: transparent;\n","    border-bottom-color: var(--fill-color);\n","    animation:\n","      spin 1s steps(1) infinite;\n","  }\n","\n","  @keyframes spin {\n","    0% {\n","      border-color: transparent;\n","      border-bottom-color: var(--fill-color);\n","      border-left-color: var(--fill-color);\n","    }\n","    20% {\n","      border-color: transparent;\n","      border-left-color: var(--fill-color);\n","      border-top-color: var(--fill-color);\n","    }\n","    30% {\n","      border-color: transparent;\n","      border-left-color: var(--fill-color);\n","      border-top-color: var(--fill-color);\n","      border-right-color: var(--fill-color);\n","    }\n","    40% {\n","      border-color: transparent;\n","      border-right-color: var(--fill-color);\n","      border-top-color: var(--fill-color);\n","    }\n","    60% {\n","      border-color: transparent;\n","      border-right-color: var(--fill-color);\n","    }\n","    80% {\n","      border-color: transparent;\n","      border-right-color: var(--fill-color);\n","      border-bottom-color: var(--fill-color);\n","    }\n","    90% {\n","      border-color: transparent;\n","      border-bottom-color: var(--fill-color);\n","    }\n","  }\n","</style>\n","\n","  <script>\n","    async function quickchart(key) {\n","      const quickchartButtonEl =\n","        document.querySelector('#' + key + ' button');\n","      quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n","      quickchartButtonEl.classList.add('colab-df-spinner');\n","      try {\n","        const charts = await google.colab.kernel.invokeFunction(\n","            'suggestCharts', [key], {});\n","      } catch (error) {\n","        console.error('Error during call to suggestCharts:', error);\n","      }\n","      quickchartButtonEl.classList.remove('colab-df-spinner');\n","      quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n","    }\n","    (() => {\n","      let quickchartButtonEl =\n","        document.querySelector('#df-417b2d44-d7ee-43ea-8d7c-20b771125f50 button');\n","      quickchartButtonEl.style.display =\n","        google.colab.kernel.accessAllowed ? 'block' : 'none';\n","    })();\n","  </script>\n","</div>\n","    </div>\n","  </div>\n"],"application/vnd.google.colaboratory.intrinsic+json":{"type":"dataframe","variable_name":"data"}},"metadata":{},"execution_count":7}]},{"cell_type":"markdown","source":["# Save dataframe to file\n"],"metadata":{"id":"Q-5IldZULkT3"}},{"cell_type":"code","source":["data.to_csv('data.csv')"],"metadata":{"id":"HNf8TXOHTDZR"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["# Function to handle string lists\n","\n","This function, named `cleanString`, is designed to process and clean a string containing numerical values. The steps performed by the function are as follows:\n","\n","1. **Remove Ellipsis and Extra Spaces:**\n","   - The function uses regular expressions to remove any occurrences of ellipsis ('...') from the input string.\n","   - It then utilizes the `re.sub` function to replace multiple consecutive spaces with a single space.\n","\n","2. **Add a Zero After the Decimal Point:**\n","   - The function appends a zero after the decimal point for single-digit integers in the cleaned string. For example, '2. ' becomes '2.0 '.\n","\n","3. **Replace the Last '...' with ']':**\n","   - The function replaces the last occurrence of '...' in the cleaned string with ']'.\n","\n","4. **Remove Brackets and Split by Space:**\n","   - The function removes the leading and trailing brackets from the cleaned string.\n","   - It then splits the string into individual values based on spaces.\n","\n","5. **Convert to Numpy Array:**\n","   - The resulting split values are converted into a NumPy array of floating-point numbers using `np.array`.\n","\n","6. **Return Resulting Array:**\n","   - The final cleaned and processed array is returned by the function.\n","\n","To use this function, pass a string containing numerical values to it, and it will return a NumPy array after the specified cleaning operations."],"metadata":{"id":"Dvx-mqV1LtYE"}},{"cell_type":"code","source":["def cleanString(input_str):\n","\n","    # Remove ellipsis and extra spaces\n","    cleaned_str = re.sub(r'\\.{3}', '', input_str)\n","    cleaned_str = ' '.join(cleaned_str.split())\n","\n","    # Add a zero after the decimal point for single-digit integers\n","    cleaned_str = cleaned_str.replace('. ', '.0 ')\n","\n","    # Replace the last '...' with ']'\n","    cleaned_str = cleaned_str.replace('...', ']')\n","\n","    input_str = ' '.join(cleaned_str.split())\n","\n","    # Remove brackets and split by space\n","    split_values = input_str[1:-1].split()\n","\n","    # Convert to numpy array\n","    result_array = np.array(split_values, dtype=float)\n","\n","    return result_array\n","\n"],"metadata":{"id":"OYlbhrXzcbjQ"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["# Extracting image features\n","\n","This code loads data from a CSV file named \"data.csv\" into a Pandas DataFrame (`df`). It then extracts the \"image_features\" column as a list of strings and processes each string using the `cleanString` function. The cleaned results are stored in a new list named `listOfArrays`.\n","\n","The DataFrame (`df`) is subsequently updated with the cleaned image features and a subset of selected columns. The selected columns include \"external_code,\" \"retail,\" \"category_encoded,\" \"fabric_encoded,\" \"color_encoded,\" and individual dimensions of the image features.\n","\n","After processing, the resulting DataFrame is displayed, showing columns such as \"external_code,\" \"retail,\" \"category_encoded,\" \"fabric_encoded,\" \"color_encoded,\" and individual dimensions of the image features.\n","\n","Note: Ensure the CSV file \"data.csv\" is in the correct directory, and adjust the column names as needed for your specific dataset."],"metadata":{"id":"7BIQrbpML-ig"}},{"cell_type":"code","source":["# Load the CSV file\n","df = pd.read_csv(\"/content/data.csv\")\n","\n","# Extract the image features array\n","image_features_list = df[\"image_features\"].tolist()\n","\n","listOfArrays = []\n","for str in image_features_list:\n","\n","    # Replace multiple spaces with a single space\n","    input_str = ' '.join(str.split())\n","    result_array = cleanString(input_str)\n","    listOfArrays.append(result_array)\n","\n","df['image_features'] = listOfArrays\n","\n","df =df[[\"external_code\", \"retail\", \"category_encoded\",\n","                    \"fabric_encoded\", \"color_encoded\", '0', '1', '2', '3', '4',\n","                    '5', '6', '7', '8', '9', '10', '11','image_features']]\n","\n","# Print the resulting DataFrame\n","print(df.columns)\n"],"metadata":{"id":"bcOWcxXTmJgi"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["# Exracting goolge trend features\n","\n","the code integrates sales and Google Trends data for each product by extracting relevant information from the sales DataFrame, defining a date range, and retrieving corresponding Google Trends data. The results are organized into a list named \"gtrends,\" containing 2D arrays for each product's category, color, and fabric Google Trends data over the specified time range through the following operations:\n","\n","1. **Read DataFrames from CSV Files:**\n","   - It reads two CSV files into Pandas DataFrames: \"sales.csv\" and \"vis2_gtrends_data.csv\" located in the \"/content/visuelle2/\" directory.\n","\n","2. **Iterate Over Rows of Sales DataFrame:**\n","   - It iterates over each row of the \"sales_df\" DataFrame representing sales data.\n","   - For each row, it extracts product information such as category (\"cat\"), color (\"col\"), fabric (\"fab\"), and release date (\"start_date\").\n","\n","3. **Date Range Calculation:**\n","   - It converts the release date to a datetime object and calculates the end date as the start date plus 52 weeks.\n","\n","4. **Date Formatting:**\n","   - It formats the start and end dates as strings in the \"YYYY-MM-DD\" format.\n","\n","5. **Filter and Extract Google Trends Data:**\n","   - It filters the \"gtrends_df\" DataFrame based on the calculated date range and the specified columns (category, color, fabric).\n","   - Extracts the values of the specified columns as NumPy arrays.\n","\n","6. **Stack Arrays and Append to List:**\n","   - It stacks the extracted arrays vertically into a 2D array named \"multitrends.\"\n","   - Appends the 2D array to the \"gtrends\" list.\n","\n"],"metadata":{"id":"tmfdbZF8M1Ja"}},{"cell_type":"code","source":["import pandas as pd\n","\n","# Read the sales data frame from a csv file\n","sales_df = pd.read_csv(\"/content/visuelle2/sales.csv\")\n","\n","# Read the gtrends data frame from a csv file\n","gtrends_df = pd.read_csv(\"/content/visuelle2/vis2_gtrends_data.csv\")\n","\n","# Create an empty list to store the trends data\n","gtrends = []\n","\n","# Iterate over each row of the sales data frame\n","for index, row in sales_df.iterrows():\n","    # Get the product information from the row\n","    cat, col, fab, start_date = row[\"category\"], row[\"color\"], row[\"fabric\"], row[\"release_date\"]\n","\n","    # Convert the start date to a datetime object\n","    start_date = pd.to_datetime(start_date)\n","\n","    # Calculate the end date as the start date plus 52 weeks\n","    end_date = start_date + pd.DateOffset(weeks=52)\n","\n","    # Format the start and end dates as strings in YYYY-MM-DD format\n","    start_date_str = start_date.strftime(\"%Y-%m-%d\")\n","    end_date_str = end_date.strftime(\"%Y-%m-%d\")\n","\n","    # Get the gtrends data for the corresponding category, color, and fabric\n","    # Use the loc function to filter the gtrends data frame by the date range and the columns\n","    gtrends_data = gtrends_df.loc[(gtrends_df[\"date\"] >= start_date_str) & (gtrends_df[\"date\"] <= end_date_str), [cat, col, fab]]\n","\n","    # Get the values of the three columns as numpy arrays\n","    cat_gtrend = gtrends_data[cat].values\n","    col_gtrend = gtrends_data[col].values\n","    fab_gtrend = gtrends_data[fab].values\n","\n","    # Stack the three arrays into a 2D array\n","    multitrends = np.vstack([cat_gtrend, col_gtrend, fab_gtrend])\n","\n","    # Append the 2D array to the gtrends list\n","    gtrends.append(multitrends)\n"],"metadata":{"id":"6896GoTzCGo5"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["# Adding to dataframe\n","\n","This code snippet adds new columns to the DataFrame (`df`) based on the Google Trends data stored in the \"gtrends\" list:\n","\n","1. **\"cat_gtrend\" Column:**\n","   - It uses the apply function to extract the category Google Trends data for each row from the \"gtrends\" list.\n","   - The lambda function takes the row index (x.name) to access the corresponding 2D array and extracts the first array ([0]) representing category trends.\n","\n","2. **\"col_gtrend\" Column:**\n","   - Similarly, it uses the apply function to extract the color Google Trends data for each row from the \"gtrends\" list.\n","   - The lambda function accesses the corresponding 2D array and extracts the second array ([1]) representing color trends.\n","\n","3. **\"fab_gtrend\" Column:**\n","   - It uses the apply function to extract the fabric Google Trends data for each row from the \"gtrends\" list.\n","   - The lambda function accesses the corresponding 2D array and extracts the third array ([2]) representing fabric trends."],"metadata":{"id":"X8DfbuUANF9e"}},{"cell_type":"code","source":["df[\"cat_gtrend\"] = df.apply(lambda x: gtrends[x.name][0], axis=1)\n","df[\"col_gtrend\"] = df.apply(lambda x: gtrends[x.name][1], axis=1)\n","df[\"fab_gtrend\"] = df.apply(lambda x: gtrends[x.name][2], axis=1)"],"metadata":{"id":"yM5Tn4L_GD36"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["# Save final dataframe"],"metadata":{"id":"CRlo1M7jNcp6"}},{"cell_type":"code","source":["#save to csv\n","df.to_csv('dataFinal.csv')\n","print(df)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"wbr6H7CMCEGi","outputId":"8c7c368b-5c1e-4843-b765-1390b4a147d3"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["        external_code  retail  category_encoded  fabric_encoded  \\\n","0                   5      36                11               0   \n","1                   2      51                11               0   \n","2                   5      10                11               0   \n","3                   9      41                 1              49   \n","4                   5      13                11               0   \n","...               ...     ...               ...             ...   \n","106845           5504      51                14              18   \n","106846           5558      10                14              18   \n","106847           4988     108                14               7   \n","106848           4280     105                 1              28   \n","106849           4791      28                24              41   \n","\n","        color_encoded    0    1    2    3    4  ...    6    7    8    9   10  \\\n","0                   4  1.0  3.0  1.0  1.0  2.0  ...  0.0  0.0  2.0  0.0  0.0   \n","1                   7  1.0  1.0  1.0  0.0  0.0  ...  0.0  0.0  0.0  1.0  1.0   \n","2                   4  1.0  3.0  1.0  0.0  1.0  ...  1.0  1.0  1.0  0.0  0.0   \n","3                   9  1.0  1.0  1.0  1.0  0.0  ...  0.0  1.0  0.0  1.0  0.0   \n","4                   4  1.0  2.0  4.0  0.0  3.0  ...  2.0  1.0  0.0  0.0  0.0   \n","...               ...  ...  ...  ...  ...  ...  ...  ...  ...  ...  ...  ...   \n","106845              4  2.0  1.0  1.0  3.0  3.0  ...  0.0  0.0  0.0  0.0  0.0   \n","106846              0  3.0  1.0  0.0  1.0  0.0  ...  0.0  2.0  1.0  0.0  0.0   \n","106847              0  1.0  0.0  0.0  1.0  2.0  ...  5.0  2.0  0.0  0.0  0.0   \n","106848              1  1.0  2.0  4.0  1.0  2.0  ...  1.0  0.0  0.0  0.0  0.0   \n","106849              2  1.0  0.0  1.0  1.0  1.0  ...  0.0  0.0  0.0  1.0  0.0   \n","\n","         11                        image_features  \\\n","0       0.0        [0.0, 0.0, 0.0, 0.0, 0.0, 0.0]   \n","1       0.0   [0.0, 0.0, 0.0, 7.260304, 0.0, 0.0]   \n","2       1.0        [0.0, 0.0, 0.0, 0.0, 0.0, 0.0]   \n","3       0.0        [0.0, 0.0, 0.0, 0.0, 0.0, 0.0]   \n","4       0.0        [0.0, 0.0, 0.0, 0.0, 0.0, 0.0]   \n","...     ...                                   ...   \n","106845  0.0  [0.0, 0.0, 0.0, 0.0, 11.033792, 0.0]   \n","106846  0.0  [0.0, 0.0, 0.0, 0.0, 10.992341, 0.0]   \n","106847  0.0        [0.0, 0.0, 0.0, 0.0, 0.0, 0.0]   \n","106848  0.0        [0.0, 0.0, 0.0, 0.0, 0.0, 0.0]   \n","106849  0.0        [0.0, 0.0, 0.0, 0.0, 0.0, 0.0]   \n","\n","                                               cat_gtrend  \\\n","0       [85.0, 84.0, 76.0, 65.0, 61.0, 59.0, 54.0, 53....   \n","1       [85.0, 84.0, 76.0, 65.0, 61.0, 59.0, 54.0, 53....   \n","2       [85.0, 84.0, 76.0, 65.0, 61.0, 59.0, 54.0, 53....   \n","3       [46.0, 52.0, 48.0, 47.0, 47.0, 48.0, 35.0, 56....   \n","4       [85.0, 84.0, 76.0, 65.0, 61.0, 59.0, 54.0, 53....   \n","...                                                   ...   \n","106845                                                 []   \n","106846                                                 []   \n","106847                                                 []   \n","106848                                                 []   \n","106849                                                 []   \n","\n","                                               col_gtrend  \\\n","0       [20.0, 18.0, 18.0, 16.0, 18.0, 19.0, 17.0, 18....   \n","1       [56.0, 58.0, 59.0, 54.0, 58.0, 55.0, 58.0, 59....   \n","2       [20.0, 18.0, 18.0, 16.0, 18.0, 19.0, 17.0, 18....   \n","3       [72.0, 73.0, 71.0, 74.0, 74.0, 74.0, 75.0, 77....   \n","4       [20.0, 18.0, 18.0, 16.0, 18.0, 19.0, 17.0, 18....   \n","...                                                   ...   \n","106845                                                 []   \n","106846                                                 []   \n","106847                                                 []   \n","106848                                                 []   \n","106849                                                 []   \n","\n","                                               fab_gtrend  \n","0       [68.0, 69.0, 71.0, 78.0, 72.0, 69.0, 66.0, 69....  \n","1       [68.0, 69.0, 71.0, 78.0, 72.0, 69.0, 66.0, 69....  \n","2       [68.0, 69.0, 71.0, 78.0, 72.0, 69.0, 66.0, 69....  \n","3       [0.0, 17.0, 18.0, 0.0, 0.0, 0.0, 0.0, 17.0, 0....  \n","4       [68.0, 69.0, 71.0, 78.0, 72.0, 69.0, 66.0, 69....  \n","...                                                   ...  \n","106845                                                 []  \n","106846                                                 []  \n","106847                                                 []  \n","106848                                                 []  \n","106849                                                 []  \n","\n","[106850 rows x 21 columns]\n"]}]}]}