{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kmLNuH5nktTT"
      },
      "source": [
        "##**Installations**\n",
        "\n",
        "- Installing **darts**\n",
        "- Installing **Optuna**\n",
        "- Installing **Plotly**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "6v2Sm_kbSk_3"
      },
      "outputs": [],
      "source": [
        "%%capture\n",
        "!pip install darts\n",
        "!pip install optuna\n",
        "!pip install plotly\n",
        "!pip install lightgbm"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "p9jihBkhmehT",
        "outputId": "ba7838ee-2508-4093-c000-d356271707bf"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Success\n"
          ]
        }
      ],
      "source": [
        "try:\n",
        "    import darts\n",
        "    import optuna\n",
        "    import plotly\n",
        "    import lightgbm\n",
        "    print(\"Success\")\n",
        "except ImportError:\n",
        "    print(\"Failed to import packages\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wy6u-FWr_iGC"
      },
      "source": [
        "##**Imports**\n",
        "\n",
        "In this cell, we import all the necessary modules for our analysis.\n",
        "\n",
        "- **Numpy and Pandas:** These are fundamental packages for scientific computing and data manipulation in Python.\n",
        "- **Matplotlib:** This is a plotting library that we'll use for data visualization.\n",
        "- **Sklearn:** We'll use this library for data preprocessing and performance metrics.\n",
        "- **Optuna:** This is a hyperparameter optimization framework, which we'll use to tune our N-BEATS model.\n",
        "- **Darts:** This library provides us with utilities for time series processing and models, including the N-BEATS model.\n",
        "- **Google Colab:** We use Google Colab's drive module to mount our Google Drive where our data is stored.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "PyThSeMDTYjZ",
        "outputId": "c063eaf7-aa48-400a-d11d-3147e0b95d99"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ],
      "source": [
        "# @title\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "%matplotlib inline\n",
        "from typing import Union, List\n",
        "from sklearn.preprocessing import MaxAbsScaler\n",
        "from IPython.display import display\n",
        "import time\n",
        "import gc\n",
        "#import seaborn as sns\n",
        "\n",
        "#plotly\n",
        "import plotly.graph_objects as go\n",
        "from plotly.subplots import make_subplots\n",
        "\n",
        "\n",
        "# optuna hyperparameter\n",
        "import optuna\n",
        "from optuna.integration import PyTorchLightningPruningCallback\n",
        "import optuna.visualization as ovis\n",
        "\n",
        "#darts imports\n",
        "from darts import TimeSeries\n",
        "from darts.models import NaiveSeasonal, NaiveDrift, ExponentialSmoothing, VARIMA, AutoARIMA\n",
        "from darts.models import RNNModel, NBEATSModel, NLinearModel, DLinearModel, LightGBMModel, NaiveMean, NaiveSeasonal, NaiveDrift, LinearRegressionModel, RandomForest\n",
        "from darts.dataprocessing.transformers import Scaler, MissingValuesFiller, InvertibleMapper\n",
        "from darts.metrics import mape, smape, mae, r2_score, mse, smape, mase,rmse, rmsle\n",
        "from darts.utils.timeseries_generation import (gaussian_timeseries,linear_timeseries,sine_timeseries)\n",
        "from darts.dataprocessing import Pipeline\n",
        "\n",
        "#Validation Imports\n",
        "from sklearn.model_selection import TimeSeriesSplit\n",
        "from sklearn.metrics import mean_squared_error\n",
        "import statsmodels.api as sm\n",
        "from sklearn.model_selection._split import _BaseKFold, indexable, _num_samples\n",
        "from sklearn.utils.validation import _deprecate_positional_args\n",
        "from sklearn.preprocessing import LabelEncoder\n",
        "\n",
        "# Drive mount\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive')     #Drive abcr5914\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NikcZTp9ARaC"
      },
      "source": [
        "##**Required Functions**\n",
        "\n",
        "The ***below code block*** contains a collection of helper functions that are used in various parts of the notebook for tasks such as preprocessing, model training, and evaluation. Below is a brief description of each function:\n",
        "- **fit_predict_and_evaluate:** This function fits the model to the training data, makes predictions, and evaluates the model's performance using Mean Absolute Error (MAE) and Symmetric Mean Absolute Percentage Error (sMAPE). This function encapsulates the entire process of training, predicting, and evaluating a model.\n",
        "```python\n",
        "def fit_predict_and_evaluate(model, training_set, validation_set, n_forecasts, model_name='Model'):\n",
        "```"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "BC1Nifl70XK1"
      },
      "outputs": [],
      "source": [
        "def fit_predict_and_evaluate(model, training_set, validation_set, n_forecasts, past_covariates_train = None, past_covariates_validation = None, series_list=False, model_name='Model'):\n",
        "    \"\"\"\n",
        "    Fit the model to the training data, make predictions, and evaluate the metrics.\n",
        "\n",
        "    Args:\n",
        "        model: The model to be trained and used for predictions.\n",
        "        training_set: The data to train the model.\n",
        "        validation_set: The data to validate the model.\n",
        "        n_forecasts (int): The number of forecast steps.\n",
        "        past_covariates_train: The past covariates for training.\n",
        "        past_covariates_validation: The past covariates for validation.\n",
        "        series_list (bool, optional): If True, the training_set will be passed as a series to the predict method. Defaults to False.\n",
        "        model_name (str, optional): The name of the model. Defaults to 'Model'.\n",
        "\n",
        "    Returns:\n",
        "        dict: A dictionary containing the forecast and the metrics.\n",
        "\n",
        "    Raises:\n",
        "        ValueError: If the lengths of actual_values and predicted_values are not the same.\n",
        "    \"\"\"\n",
        "    # Validate inputs\n",
        "    if not model or not training_set or n_forecasts < 1:\n",
        "        raise ValueError(\"Invalid inputs provided.\")\n",
        "\n",
        "    # Fit the model and make predictions\n",
        "    try:\n",
        "        train_start = time.time()\n",
        "        model.fit(training_set, past_covariates=past_covariates_train)\n",
        "        train_stop = time.time()\n",
        "        forecast_start = time.time()\n",
        "        forecast = model.predict(n_forecasts, series=training_set if series_list else None, past_covariates=past_covariates_validation, show_warnings=False)\n",
        "        forecast_stop = time.time()\n",
        "    except Exception as e:\n",
        "        print(f\"An error occurred while fitting the model or making predictions: {e}\")\n",
        "        return None\n",
        "\n",
        "    # Validate the forecast and actual values length\n",
        "    #if len(validation_set) != len(forecast):\n",
        "     #   raise ValueError(\"Lengths of validation_set and forecast must be the same.\")\n",
        "\n",
        "\n",
        "    mae_value = mae(validation_set, forecast, inter_reduction = np.mean)\n",
        "    smape_value = smape(validation_set, forecast, inter_reduction = np.mean)\n",
        "    rmse_value = rmse(validation_set, forecast, inter_reduction = np.mean)\n",
        "\n",
        "    train_time = train_stop-train_start\n",
        "    forecast_time = forecast_stop - forecast_start\n",
        "\n",
        "    print('-----------------------------------------')\n",
        "    print(f\"MAE ({model_name}) = {mae_value:.2f}\")\n",
        "    print(f\"sMAPE ({model_name}) = {smape_value:.2f}\")\n",
        "    print(f\"RMSE ({model_name}) = {rmse_value:.2f}\")\n",
        "    print(f\"Training Time ({model_name}) = {train_time:.2f}sec\")\n",
        "    print(f\"Forecast Time ({model_name}) = {forecast_time:.2f}sec\")\n",
        "    print(f\"Total Time ({model_name}) = {train_time+forecast_time:.2f}sec\")\n",
        "    print('-----------------------------------------')\n",
        "\n",
        "    return {'forecast': forecast, 'MAE': mae_value, 'sMAPE': smape_value, 'RMSE': rmse_value, 'Training Time': train_time, 'Forecast Time': forecast_time, 'Total Time': train_time+forecast_time}\n",
        "\n",
        "'----------------------------------------------------------------------------------------------------'\n",
        "\n",
        "\n",
        "def extend_index_with_past(input_chunk_length, train_idx, test_idx, dataframe, gap = False):\n",
        "    \"\"\"\n",
        "    Extends the first index in the list with its previous indexes based on input_chunk_length.\n",
        "\n",
        "    Parameters:\n",
        "    input_chunk_length (int): Number of previous indexes to include.\n",
        "    indexes (list): List of indexes from the DataFrame.\n",
        "    dataframe (DataFrame): The DataFrame from which indexes are derived.\n",
        "\n",
        "    Returns:\n",
        "    list: Extended list of indexes including the range from the first index and its previous indexes.\n",
        "    \"\"\"\n",
        "    if not train_idx or dataframe.empty:\n",
        "        return []\n",
        "\n",
        "    index = max(train_idx)\n",
        "    # Ensuring the start index does not fall below the DataFrame's minimum index\n",
        "    start_index = max(index - input_chunk_length, dataframe.index.min())\n",
        "\n",
        "    extended_indexes = list(range(start_index+1, index + 1))+ test_idx if gap == True else list(range(start_index + 1, max(test_idx) + 1))\n",
        "    return extended_indexes\n",
        "\n",
        "\n",
        "'----------------------------------------------------------------------------------------------------'\n",
        "\n",
        "def add_metrics_to_df(df, store_id, dept_id, model_name, mae, smape, rmse, training_time, forecast_time, total_time, dataset_size):\n",
        "    new_row = pd.DataFrame({\n",
        "        'Store ID': [store_id],\n",
        "        'Dept ID': [dept_id],\n",
        "        'Model Name': [model_name],\n",
        "        'MAE': [mae],\n",
        "        'sMAPE': [smape],\n",
        "        'RMSE': [rmse],\n",
        "        'Training Time(seconds)': [training_time],\n",
        "        'Forecast Time(seconds)': [forecast_time],\n",
        "        'Total Time(seconds)': [total_time],\n",
        "        'Dataset Size(MB)': [dataset_size]\n",
        "    })\n",
        "    df = pd.concat([df, new_row])\n",
        "    return df\n",
        "\n",
        "'-------------------------------------------------------------------------------------------------------'\n",
        "# Function to load datasets\n",
        "def load_dataset(path):\n",
        "    return pd.read_csv(path)\n",
        "\n",
        "'-------------------------------------------------------------------------------------------------------'\n",
        "\n",
        "# Function to convert and one-hot encode events\n",
        "def one_hot_encode_and_join(original_dataframe, feature_to_encode, new_name=None):\n",
        "    dummies = pd.get_dummies(original_dataframe[feature_to_encode].fillna('No_Event'), prefix=new_name)\n",
        "    return original_dataframe.drop(feature_to_encode, axis=1).join(dummies)\n",
        "\n",
        "'-------------------------------------------------------------------------------------------------------'\n",
        "\n",
        "# Creating the DataFrame\n",
        "columns = ['Store ID', 'Dept ID', 'Model Name', 'MAE', 'sMAPE', 'RMSE', 'Training Time(seconds)', 'Forecast Time(seconds)', 'Total Time(seconds)',\n",
        "           'Dataset Size(MB)']\n",
        "metrics_df = pd.DataFrame(columns=columns)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "y2cumUb3DWhS"
      },
      "source": [
        "\n",
        "## **Model Creation Functions**\n",
        "\n",
        "This notebook contains functions for creating instances of various types of models. Each function takes in a set of parameters and returns a model instance with those parameters.\n",
        "\n",
        "1. **Nbeats Model** : <br>\n",
        "This function creates and returns an **`NBEATS Model`** with specified parameters.\n",
        "```python\n",
        "create_nbeats_model(input_chunk_length=24, output_chunk_length=24, generic_architecture=True,\n",
        "               num_stacks=4, num_blocks=2, num_layers=2, layer_widths=16,\n",
        "               n_epochs=1, nr_epochs_val_period=1, batch_size=32, model_name=\"NBEATS\")\n",
        "```\n",
        "2. **DLinear Model** : <br>\n",
        "This function creates an instance of **`DLinearModel`** with the specified parameters.\n",
        "```python\n",
        "create_dlinear_model(input_chunk_length=24, output_chunk_length=24, n_epochs=2,\n",
        "                        batch_size=16, shared_weights=False, kernel_size=25,\n",
        "                        const_init=True, use_static_covariates=True):\n",
        "```\n",
        "\n",
        "3. **NLinear Model** : <br>\n",
        "This Function creates an instance of **`NLinearModel`** with the specified parameters.\n",
        "```python\n",
        "create_nlinear_model(input_chunk_length=24, output_chunk_length=24, n_epochs=2,\n",
        "                         shared_weights=False, const_init=True, normalize=False,\n",
        "                         use_static_covariates=True):\n",
        "```\n",
        "\n",
        "4. **LightGBM Model**: <br>\n",
        "This function creates an instance of LightGBMModel with the specified parameters.\n",
        "```python\n",
        "create_lightgbm_model(lags=12, output_chunk_length=1, max_depth=3,\n",
        "                          n_estimators=50, learning_rate=0.1, verbose=-1,num_leaves=31,\n",
        "                          lags_past_covariates = None, min_data_in_leaf=20,extra_trees=True)\n",
        "```"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "id": "FlU3DPMp0kzY"
      },
      "outputs": [],
      "source": [
        "def create_nbeats_model(input_chunk_length=24, output_chunk_length=24, generic_architecture=True,\n",
        "               num_stacks=4, num_blocks=2, num_layers=2, layer_widths=16,\n",
        "               n_epochs=2, nr_epochs_val_period=1, batch_size=32, model_name=\"NBEATS\"):\n",
        "    \"\"\"\n",
        "    Create and return an NBEATSModel with the specified parameters.\n",
        "\n",
        "    Args:\n",
        "        input_chunk_length (int): The length of the input sequence.\n",
        "        output_chunk_length (int): The length of the output sequence.\n",
        "        generic_architecture (bool): Whether to use the generic architecture.\n",
        "        num_stacks (int): The number of stacks.\n",
        "        num_blocks (int): The number of blocks per stack.\n",
        "        num_layers (int): The number of layers per block.\n",
        "        layer_widths (int): The number of units per layer.\n",
        "        n_epochs (int): The number of epochs.\n",
        "        nr_epochs_val_period (int): The number of epochs between each validation set evaluation.\n",
        "        batch_size (int): The size of the batch.\n",
        "        model_name (str): The name of the model.\n",
        "\n",
        "    Returns:\n",
        "        NBEATSModel: A trained NBEATSModel.\n",
        "    \"\"\"\n",
        "    model_nbeats = NBEATSModel(\n",
        "        input_chunk_length=input_chunk_length,\n",
        "        output_chunk_length=output_chunk_length,\n",
        "        generic_architecture=generic_architecture,\n",
        "        num_stacks=num_stacks,\n",
        "        num_blocks=num_blocks,\n",
        "        num_layers=num_layers,\n",
        "        layer_widths=layer_widths,\n",
        "        n_epochs=n_epochs,\n",
        "        nr_epochs_val_period=nr_epochs_val_period,\n",
        "        batch_size=batch_size,\n",
        "        model_name=model_name\n",
        "    )\n",
        "\n",
        "    return model_nbeats\n",
        "\n",
        "def create_nlinear_model(input_chunk_length=24, output_chunk_length=24, n_epochs=2,\n",
        "                         shared_weights=False, const_init=True, normalize=False,\n",
        "                         use_static_covariates=True):\n",
        "    \"\"\"\n",
        "    Creates an instance of NLinearModel with the specified parameters.\n",
        "\n",
        "    Parameters:\n",
        "    input_chunk_length (int): Length of the input chunks.\n",
        "    output_chunk_length (int): Length of the output chunks.\n",
        "    n_epochs (int): Number of epochs for training.\n",
        "    shared_weights (bool): If True, the model will share weights.\n",
        "    const_init (bool): If True, the model will have constant initialization.\n",
        "    normalize (bool): If True, the model will use normalization.\n",
        "    use_static_covariates (bool): If True, the model will use static covariates.\n",
        "\n",
        "    Returns:\n",
        "    model (NLinearModel): An instance of NLinearModel.\n",
        "    \"\"\"\n",
        "\n",
        "    model = NLinearModel(\n",
        "        input_chunk_length=input_chunk_length,\n",
        "        output_chunk_length=output_chunk_length,\n",
        "        n_epochs=n_epochs,\n",
        "        shared_weights=shared_weights,\n",
        "        const_init=const_init,\n",
        "        normalize=normalize,\n",
        "        use_static_covariates=use_static_covariates,\n",
        "    )\n",
        "\n",
        "    return model\n",
        "\n",
        "def create_dlinear_model(input_chunk_length=24,\n",
        "                         output_chunk_length=24,\n",
        "                         n_epochs=2,\n",
        "                         batch_size=16,\n",
        "                         shared_weights=False,\n",
        "                         kernel_size=25,\n",
        "                         const_init=True,\n",
        "                         use_static_covariates=True):\n",
        "    \"\"\"\n",
        "    Creates an instance of DLinearModel with the specified parameters.\n",
        "\n",
        "    Parameters:\n",
        "    input_chunk_length (int): Length of the input chunks.\n",
        "    output_chunk_length (int): Length of the output chunks.\n",
        "    n_epochs (int): Number of epochs for training.\n",
        "    batch_size (int): Batch size for training.\n",
        "    shared_weights (bool): If True, the model will share weights.\n",
        "    kernel_size (int): Size of the kernels in the model.\n",
        "    const_init (bool): If True, the model will have constant initialization.\n",
        "    use_static_covariates (bool): If True, the model will use static covariates.\n",
        "\n",
        "    Returns:\n",
        "    model (DLinearModel): An instance of DLinearModel.\n",
        "    \"\"\"\n",
        "\n",
        "    model = DLinearModel(\n",
        "        input_chunk_length=input_chunk_length,\n",
        "        output_chunk_length=output_chunk_length,\n",
        "        n_epochs=n_epochs,\n",
        "        batch_size=batch_size,\n",
        "        shared_weights=shared_weights,\n",
        "        kernel_size=kernel_size,\n",
        "        const_init=const_init,\n",
        "        use_static_covariates=use_static_covariates\n",
        "    )\n",
        "\n",
        "    return model\n",
        "\n",
        "\n",
        "def create_lightgbm_model(lags=12,\n",
        "                          output_chunk_length=1,\n",
        "                          max_depth=3,\n",
        "                          n_estimators=50,\n",
        "                          learning_rate=0.1,verbose =-1,use_static_covariates = False,num_leaves=31,lags_past_covariates = None, min_data_in_leaf=20,extra_trees=True):\n",
        "    \"\"\"\n",
        "    Creates an instance of LightGBMModel with the specified parameters.\n",
        "\n",
        "    Parameters:\n",
        "    lags (int): Number of lags to use in the model.\n",
        "    output_chunk_length (int): Length of the output chunks.\n",
        "    max_depth (int): Maximum depth of the trees.\n",
        "    n_estimators (int): Number of trees in the model.\n",
        "    learning_rate (float): Learning rate for the model.\n",
        "\n",
        "    Returns:\n",
        "    model (LightGBMModel): An instance of LightGBMModel.\n",
        "    \"\"\"\n",
        "\n",
        "    model = LightGBMModel(\n",
        "        lags=lags,\n",
        "        output_chunk_length=output_chunk_length,\n",
        "        max_depth=max_depth,\n",
        "        n_estimators=n_estimators,\n",
        "        learning_rate=learning_rate,\n",
        "        verbose=verbose,\n",
        "        num_leaves=num_leaves,\n",
        "        min_data_in_leaf=min_data_in_leaf,\n",
        "        extra_trees=extra_trees,\n",
        "        lags_past_covariates = lags_past_covariates\n",
        "    )\n",
        "\n",
        "    return model\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yn4m6NZYvEW8"
      },
      "source": [
        "# **free_ram_memory function**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "id": "brjmLlAAtZVI"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "\n",
        "def reduce_memory(df, verbose=True):\n",
        "    \"\"\"Reduce memory of a DataFrame by downcasting numeric types.\"\"\"\n",
        "\n",
        "    # Initial memory\n",
        "    start_mem = df.memory_usage().sum() / 1024**2\n",
        "\n",
        "    # Define numeric types and their downcast\n",
        "    type_mapping = {\n",
        "        'int': [(np.int8, np.iinfo(np.int8)),\n",
        "                (np.int16, np.iinfo(np.int16)),\n",
        "                (np.int32, np.iinfo(np.int32)),\n",
        "                (np.int64, np.iinfo(np.int64))],\n",
        "\n",
        "        'float': [(np.float16, np.finfo(np.float16)),\n",
        "                  (np.float32, np.finfo(np.float32)),\n",
        "                  (np.float64, np.finfo(np.float64))]\n",
        "    }\n",
        "\n",
        "    for col, col_type in df.dtypes.items():\n",
        "        if col_type in ['int16', 'int32', 'int64']:\n",
        "            for dtype, type_info in type_mapping['int']:\n",
        "                if type_info.min <= df[col].min() and df[col].max() <= type_info.max:\n",
        "                    df[col] = df[col].astype(dtype)\n",
        "                    break\n",
        "        elif col_type in ['float16', 'float32', 'float64']:\n",
        "            for dtype, type_info in type_mapping['float']:\n",
        "                if type_info.min <= df[col].min() and df[col].max() <= type_info.max:\n",
        "                    df[col] = df[col].astype(dtype)\n",
        "                    break\n",
        "\n",
        "    # Calculate and print memory reduction\n",
        "    end_mem = df.memory_usage().sum() / 1024**2\n",
        "    if verbose:\n",
        "        print(f'Memory usage decreased from {start_mem:.2f}MB to {end_mem:.2f}MB ({100 * (start_mem - end_mem) / start_mem:.1f}% reduction)')\n",
        "\n",
        "    return df\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "I5lY3n_Pjo4N"
      },
      "source": [
        "# M5"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Paths to the datasets\n",
        "base_path = '/content/drive/MyDrive/Master_Thesis/Datasets/M5-Forecasting-accuracy/'\n",
        "files = ['sell_prices.csv', 'sales_train_evaluation.csv', 'calendar.csv', 'sample_submission.csv']\n",
        "sell_price_df, sales_train_evaluation_df, calendar_df, submission_file = [load_dataset(base_path + file) for file in files]\n",
        "\n",
        "\n",
        "# One-hot encode 'event_name_1' and 'event_name_2'\n",
        "calendar_df = one_hot_encode_and_join(calendar_df, 'event_name_1', 'event')\n",
        "calendar_df = one_hot_encode_and_join(calendar_df, 'event_name_2', 'event2')\n",
        "calendar_df.drop(columns =['event_type_1','event_type_2'],inplace = True)\n",
        "\n",
        "stores = ['CA_1', 'CA_2', 'CA_3', 'CA_4', 'TX_1', 'TX_2', 'TX_3', 'WI_1', 'WI_2', 'WI_3']\n",
        "departments = ['HOBBIES_1', 'HOBBIES_2', 'HOUSEHOLD_1', 'HOUSEHOLD_2', 'FOODS_1', 'FOODS_2', 'FOODS_3']\n",
        "\n",
        "def get_store_dept_combinations(stores, departments):\n",
        "    for store in stores:\n",
        "        for department in departments:\n",
        "            yield store, department\n",
        "\n",
        "# Create a generator\n",
        "combinations_generator = get_store_dept_combinations(stores, departments)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 105
        },
        "id": "-xZ68OSlFHhG",
        "outputId": "ca581ff3-531e-4584-ff64-0103d5ab5ebf"
      },
      "execution_count": 66,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "\"\\n# Paths to the datasets\\nbase_path = '/content/drive/MyDrive/Master_Thesis/Datasets/M5-Forecasting-accuracy/'\\nfiles = ['sell_prices.csv', 'sales_train_evaluation.csv', 'calendar.csv', 'sample_submission.csv']\\nsell_price_df, sales_train_evaluation_df, calendar_df, submission_file = [load_dataset(base_path + file) for file in files]\\n\\n\\n# One-hot encode 'event_name_1' and 'event_name_2'\\ncalendar_df = one_hot_encode_and_join(calendar_df, 'event_name_1', 'event')\\ncalendar_df = one_hot_encode_and_join(calendar_df, 'event_name_2', 'event2')\\ncalendar_df.drop(columns =['event_type_1','event_type_2'],inplace = True)\\n\\nstores = ['CA_1', 'CA_2', 'CA_3', 'CA_4', 'TX_1', 'TX_2', 'TX_3', 'WI_1', 'WI_2', 'WI_3']\\ndepartments = ['HOBBIES_1', 'HOBBIES_2', 'HOUSEHOLD_1', 'HOUSEHOLD_2', 'FOODS_1', 'FOODS_2', 'FOODS_3']\\n\\ndef get_store_dept_combinations(stores, departments):\\n    for store in stores:\\n        for department in departments:\\n            yield store, department\\n\\n# Create a generator\\ncombinations_generator = get_store_dept_combinations(stores, departments)\\n\""
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 66
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Store and Department\n",
        "store_id, dept_id = next(combinations_generator)\n",
        "print(f'store_id = \\'{store_id}\\'')\n",
        "print(f'dept_id = \\'{dept_id}\\'')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vrC0i3QCtqd9",
        "outputId": "8804f806-8eb5-41d6-82f9-6862180dd855"
      },
      "execution_count": 67,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "store_id = 'CA_1'\n",
            "dept_id = 'FOODS_3'\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "##**Data Preprocessing**"
      ],
      "metadata": {
        "id": "uiAQxrjZsS-1"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 68,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 652
        },
        "id": "psOT7WJWqfyv",
        "outputId": "a2dd0955-4ee0-469b-afa4-04527e323b8c"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Memory usage decreased from 429.75MB to 129.41MB (69.9% reduction)\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "                                  id  value  sell_price       date  snap_CA  \\\n",
              "0        FOODS_3_001_CA_1_evaluation      1    2.279297 2011-01-29      0.0   \n",
              "4        FOODS_3_005_CA_1_evaluation      1    1.980469 2011-01-29      0.0   \n",
              "10       FOODS_3_011_CA_1_evaluation      3    1.980469 2011-01-29      0.0   \n",
              "13       FOODS_3_014_CA_1_evaluation     11    1.980469 2011-01-29      0.0   \n",
              "14       FOODS_3_015_CA_1_evaluation      5    1.580078 2011-01-29      0.0   \n",
              "...                              ...    ...         ...        ...      ...   \n",
              "1597438  FOODS_3_823_CA_1_evaluation      2    2.980469 2016-05-22      0.0   \n",
              "1597439  FOODS_3_824_CA_1_evaluation      0    2.480469 2016-05-22      0.0   \n",
              "1597440  FOODS_3_825_CA_1_evaluation      1    3.980469 2016-05-22      0.0   \n",
              "1597441  FOODS_3_826_CA_1_evaluation      1    1.280273 2016-05-22      0.0   \n",
              "1597442  FOODS_3_827_CA_1_evaluation      5    1.000000 2016-05-22      0.0   \n",
              "\n",
              "         snap_TX  snap_WI  event_Chanukah End  event_Christmas  \\\n",
              "0            0.0      0.0                 0.0              0.0   \n",
              "4            0.0      0.0                 0.0              0.0   \n",
              "10           0.0      0.0                 0.0              0.0   \n",
              "13           0.0      0.0                 0.0              0.0   \n",
              "14           0.0      0.0                 0.0              0.0   \n",
              "...          ...      ...                 ...              ...   \n",
              "1597438      0.0      0.0                 0.0              0.0   \n",
              "1597439      0.0      0.0                 0.0              0.0   \n",
              "1597440      0.0      0.0                 0.0              0.0   \n",
              "1597441      0.0      0.0                 0.0              0.0   \n",
              "1597442      0.0      0.0                 0.0              0.0   \n",
              "\n",
              "         event_Cinco De Mayo  ...  event_StPatricksDay  event_SuperBowl  \\\n",
              "0                        0.0  ...                  0.0              0.0   \n",
              "4                        0.0  ...                  0.0              0.0   \n",
              "10                       0.0  ...                  0.0              0.0   \n",
              "13                       0.0  ...                  0.0              0.0   \n",
              "14                       0.0  ...                  0.0              0.0   \n",
              "...                      ...  ...                  ...              ...   \n",
              "1597438                  0.0  ...                  0.0              0.0   \n",
              "1597439                  0.0  ...                  0.0              0.0   \n",
              "1597440                  0.0  ...                  0.0              0.0   \n",
              "1597441                  0.0  ...                  0.0              0.0   \n",
              "1597442                  0.0  ...                  0.0              0.0   \n",
              "\n",
              "         event_Thanksgiving  event_ValentinesDay  event_VeteransDay  \\\n",
              "0                       0.0                  0.0                0.0   \n",
              "4                       0.0                  0.0                0.0   \n",
              "10                      0.0                  0.0                0.0   \n",
              "13                      0.0                  0.0                0.0   \n",
              "14                      0.0                  0.0                0.0   \n",
              "...                     ...                  ...                ...   \n",
              "1597438                 0.0                  0.0                0.0   \n",
              "1597439                 0.0                  0.0                0.0   \n",
              "1597440                 0.0                  0.0                0.0   \n",
              "1597441                 0.0                  0.0                0.0   \n",
              "1597442                 0.0                  0.0                0.0   \n",
              "\n",
              "         event2_Cinco De Mayo  event2_Easter  event2_Father's day  \\\n",
              "0                         0.0            0.0                  0.0   \n",
              "4                         0.0            0.0                  0.0   \n",
              "10                        0.0            0.0                  0.0   \n",
              "13                        0.0            0.0                  0.0   \n",
              "14                        0.0            0.0                  0.0   \n",
              "...                       ...            ...                  ...   \n",
              "1597438                   0.0            0.0                  0.0   \n",
              "1597439                   0.0            0.0                  0.0   \n",
              "1597440                   0.0            0.0                  0.0   \n",
              "1597441                   0.0            0.0                  0.0   \n",
              "1597442                   0.0            0.0                  0.0   \n",
              "\n",
              "         event2_No_Event  event2_OrthodoxEaster  \n",
              "0                    1.0                    0.0  \n",
              "4                    1.0                    0.0  \n",
              "10                   1.0                    0.0  \n",
              "13                   1.0                    0.0  \n",
              "14                   1.0                    0.0  \n",
              "...                  ...                    ...  \n",
              "1597438              1.0                    0.0  \n",
              "1597439              1.0                    0.0  \n",
              "1597440              1.0                    0.0  \n",
              "1597441              1.0                    0.0  \n",
              "1597442              1.0                    0.0  \n",
              "\n",
              "[1280182 rows x 43 columns]"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-0edb958a-c555-413e-8db1-80cfb3c46b2f\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>id</th>\n",
              "      <th>value</th>\n",
              "      <th>sell_price</th>\n",
              "      <th>date</th>\n",
              "      <th>snap_CA</th>\n",
              "      <th>snap_TX</th>\n",
              "      <th>snap_WI</th>\n",
              "      <th>event_Chanukah End</th>\n",
              "      <th>event_Christmas</th>\n",
              "      <th>event_Cinco De Mayo</th>\n",
              "      <th>...</th>\n",
              "      <th>event_StPatricksDay</th>\n",
              "      <th>event_SuperBowl</th>\n",
              "      <th>event_Thanksgiving</th>\n",
              "      <th>event_ValentinesDay</th>\n",
              "      <th>event_VeteransDay</th>\n",
              "      <th>event2_Cinco De Mayo</th>\n",
              "      <th>event2_Easter</th>\n",
              "      <th>event2_Father's day</th>\n",
              "      <th>event2_No_Event</th>\n",
              "      <th>event2_OrthodoxEaster</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>FOODS_3_001_CA_1_evaluation</td>\n",
              "      <td>1</td>\n",
              "      <td>2.279297</td>\n",
              "      <td>2011-01-29</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>...</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>FOODS_3_005_CA_1_evaluation</td>\n",
              "      <td>1</td>\n",
              "      <td>1.980469</td>\n",
              "      <td>2011-01-29</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>...</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>10</th>\n",
              "      <td>FOODS_3_011_CA_1_evaluation</td>\n",
              "      <td>3</td>\n",
              "      <td>1.980469</td>\n",
              "      <td>2011-01-29</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>...</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>13</th>\n",
              "      <td>FOODS_3_014_CA_1_evaluation</td>\n",
              "      <td>11</td>\n",
              "      <td>1.980469</td>\n",
              "      <td>2011-01-29</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>...</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>14</th>\n",
              "      <td>FOODS_3_015_CA_1_evaluation</td>\n",
              "      <td>5</td>\n",
              "      <td>1.580078</td>\n",
              "      <td>2011-01-29</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>...</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1597438</th>\n",
              "      <td>FOODS_3_823_CA_1_evaluation</td>\n",
              "      <td>2</td>\n",
              "      <td>2.980469</td>\n",
              "      <td>2016-05-22</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>...</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1597439</th>\n",
              "      <td>FOODS_3_824_CA_1_evaluation</td>\n",
              "      <td>0</td>\n",
              "      <td>2.480469</td>\n",
              "      <td>2016-05-22</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>...</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1597440</th>\n",
              "      <td>FOODS_3_825_CA_1_evaluation</td>\n",
              "      <td>1</td>\n",
              "      <td>3.980469</td>\n",
              "      <td>2016-05-22</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>...</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1597441</th>\n",
              "      <td>FOODS_3_826_CA_1_evaluation</td>\n",
              "      <td>1</td>\n",
              "      <td>1.280273</td>\n",
              "      <td>2016-05-22</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>...</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1597442</th>\n",
              "      <td>FOODS_3_827_CA_1_evaluation</td>\n",
              "      <td>5</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>2016-05-22</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>...</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>1280182 rows × 43 columns</p>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-0edb958a-c555-413e-8db1-80cfb3c46b2f')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-0edb958a-c555-413e-8db1-80cfb3c46b2f button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-0edb958a-c555-413e-8db1-80cfb3c46b2f');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "<div id=\"df-bf87e813-1b3a-4b21-bbd1-28f62f0dee30\">\n",
              "  <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-bf87e813-1b3a-4b21-bbd1-28f62f0dee30')\"\n",
              "            title=\"Suggest charts\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "  </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "  <script>\n",
              "    async function quickchart(key) {\n",
              "      const quickchartButtonEl =\n",
              "        document.querySelector('#' + key + ' button');\n",
              "      quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "      quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "      try {\n",
              "        const charts = await google.colab.kernel.invokeFunction(\n",
              "            'suggestCharts', [key], {});\n",
              "      } catch (error) {\n",
              "        console.error('Error during call to suggestCharts:', error);\n",
              "      }\n",
              "      quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "      quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "    }\n",
              "    (() => {\n",
              "      let quickchartButtonEl =\n",
              "        document.querySelector('#df-bf87e813-1b3a-4b21-bbd1-28f62f0dee30 button');\n",
              "      quickchartButtonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "    })();\n",
              "  </script>\n",
              "</div>\n",
              "    </div>\n",
              "  </div>\n"
            ]
          },
          "metadata": {}
        }
      ],
      "source": [
        "# filtering sales train and sell prices based on store_id and dept_id\n",
        "sales_train_filtered = sales_train_evaluation_df.query(\"store_id == @store_id & dept_id == @dept_id\")\n",
        "sell_prices_filtered = sell_price_df.query(\"store_id == @store_id & item_id.str.contains(@dept_id)\")\n",
        "\n",
        "# merging calendar with sell prices\n",
        "merged_price_calendar = sell_prices_filtered.merge(calendar_df, on='wm_yr_wk', how='left')\n",
        "\n",
        "# melting sales train df\n",
        "melt_vars = [f'd_{i}' for i in range(1, 1942)]\n",
        "train_melt_df = sales_train_filtered.melt(id_vars=['id'], value_vars=melt_vars, var_name='d', value_name='value')\n",
        "\n",
        "# merging melted_train_df with merged price calendar\n",
        "merged_price_calendar['id'] = merged_price_calendar['item_id'] + '_' + merged_price_calendar['store_id'] + '_evaluation'\n",
        "final_df = train_melt_df.merge(merged_price_calendar, on=['id', 'd'], how='left')\n",
        "\n",
        "# Cleaning up the DataFrame\n",
        "final_df.drop(columns=['store_id', 'item_id', 'weekday', 'wday', 'month', 'year'], inplace=True)\n",
        "final_df_no_nan = final_df.dropna(subset=['date']).copy()\n",
        "final_df_no_nan['date'] = pd.to_datetime(final_df_no_nan['date'])\n",
        "columns_order = ['id', 'value', 'sell_price', 'date'] + [col for col in final_df_no_nan.columns if 'event' in col or 'snap' in col]\n",
        "formatted_df = final_df_no_nan[columns_order].copy()\n",
        "\n",
        "# Clearing up unwanted dataframes\n",
        "del train_melt_df, final_df, final_df_no_nan,merged_price_calendar,sell_prices_filtered,sales_train_filtered\n",
        "\n",
        "# Reducing memory usage\n",
        "display(reduce_memory(formatted_df, verbose=True))\n",
        "dataset_size = formatted_df.memory_usage().sum() / 1024**2\n",
        "garbage_collected = gc.collect()"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# formatted_df.to_csv(base_path + 'formatted_df.csv') # to download the csv file to the drive"
      ],
      "metadata": {
        "id": "j_WLtwlDV7DT"
      },
      "execution_count": 69,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##**TimeSeries Conversion**"
      ],
      "metadata": {
        "id": "jMSBcPEwsOMl"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 70,
      "metadata": {
        "id": "fL9BAcuxttHS"
      },
      "outputs": [],
      "source": [
        "# Prepare the data for time series analysis by sorting\n",
        "sorted_data = formatted_df.copy().sort_values(by='id')\n",
        "\n",
        "# Initializing the label encoder\n",
        "label_encoder = LabelEncoder()\n",
        "\n",
        "# Fit the encoder to the 'id' column and transform it to numeric labels\n",
        "sorted_data['id_encoded'] = label_encoder.fit_transform(sorted_data['id'])\n",
        "\n",
        "# Group by 'id' and convert the 'value' column into TimeSeries objects\n",
        "group_col = ['id_encoded']\n",
        "date_col = 'date'\n",
        "value_col = ['value']\n",
        "\n",
        "# Generate TimeSeries objects for the target variable\n",
        "grouped_time_series = TimeSeries.from_group_dataframe(\n",
        "    sorted_data,\n",
        "    group_cols=group_col,\n",
        "    time_col=date_col,\n",
        "    value_cols=value_col\n",
        ")\n",
        "\n",
        "# Set the cutoff date for training and validation sets\n",
        "split_date = pd.Timestamp('2016-04-24')\n",
        "\n",
        "# Split the data into training and validation sets\n",
        "train_set = [ts.split_before(split_date)[0] for ts in grouped_time_series]\n",
        "val_set = [ts.split_after(split_date)[1] for ts in grouped_time_series]\n",
        "\n",
        "Scale_series = Scaler()\n",
        "train_series_set = [Scale_series.fit_transform(series) for series in train_set]\n",
        "val_series_set =[Scale_series.transform(series) for series in val_set]\n",
        "\n",
        "# Gather additional features for the model\n",
        "exogenous_features = ['sell_price','snap_CA', 'snap_TX', 'snap_WI'] + \\\n",
        "    [e for e in formatted_df.columns if e.startswith('event')] + \\\n",
        "    [e for e in formatted_df.columns if e.startswith('event2')]\n",
        "\n",
        "exog_features_data = sorted_data[['id_encoded', 'date'] + exogenous_features].sort_values(by='id_encoded')\n",
        "\n",
        "# Convert the exogenous features into TimeSeries objects\n",
        "exog_features_series = TimeSeries.from_group_dataframe(\n",
        "    exog_features_data,\n",
        "    group_cols=group_col,\n",
        "    time_col=date_col,\n",
        "    value_cols=exogenous_features\n",
        ")\n",
        "\n",
        "# Split date for exogenous features\n",
        "train_exog_cutoff = pd.Timestamp('2016-04-24')\n",
        "val_exog_cutoff = pd.Timestamp('2016-03-30')\n",
        "\n",
        "# Split the exogenous features TimeSeries\n",
        "train_exog_set = [ts.split_before(train_exog_cutoff)[0] for ts in exog_features_series]\n",
        "val_exog_set = [ts.split_after(val_exog_cutoff)[1] for ts in exog_features_series]\n",
        "\n",
        "del sorted_data\n",
        "\n",
        "garbage_collected = gc.collect()"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "##**Nbeats**"
      ],
      "metadata": {
        "id": "Vi5aotRisKWZ"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 71,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 70
        },
        "id": "UJz6PuKikieG",
        "outputId": "cd372267-db93-40d5-c5a4-a82bbef8a7e4"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "\"\\n# `run_nbeats` is a function that initializes and returns a model object.\\nmodel = create_nbeats_model()\\n\\n# Then we call the `fit_predict_and_evaluate` function with the appropriate parameters.\\nresults = fit_predict_and_evaluate(\\n    model=model,\\n    training_set=train_series_set,\\n    validation_set=val_series_set,\\n    n_forecasts=28,\\n    past_covariates_train=train_exog_set,\\n    past_covariates_validation=val_exog_set,\\n    series_list=True,\\n    model_name='Nbeats'\\n)\\n\""
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 71
        }
      ],
      "source": [
        "# `run_nbeats` is a function that initializes and returns a model object.\n",
        "model = create_nbeats_model()\n",
        "\n",
        "# Then we call the `fit_predict_and_evaluate` function with the appropriate parameters.\n",
        "results = fit_predict_and_evaluate(\n",
        "    model=model,\n",
        "    training_set=train_series_set,\n",
        "    validation_set=val_series_set,\n",
        "    n_forecasts=28,\n",
        "    past_covariates_train=train_exog_set,\n",
        "    past_covariates_validation=val_exog_set,\n",
        "    series_list=True,\n",
        "    model_name='Nbeats'\n",
        ")"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "##**Lightgbm**"
      ],
      "metadata": {
        "id": "0I4q4rJfsZ3o"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "'''create_lightgbm_model(lags=12, output_chunk_length=1, max_depth=3,\n",
        "                       n_estimators=50, learning_rate=0.1, verbose=-1,num_leaves=31,\n",
        "                       lags_past_covariates = None, min_data_in_leaf=20,extra_trees=True\n",
        "'''\n",
        "model_lgbm = create_lightgbm_model(lags_past_covariates = 7,output_chunk_length=2)\n",
        "\n",
        "\n",
        "results = fit_predict_and_evaluate(\n",
        "    model=model_lgbm,\n",
        "    training_set=train_series_set,\n",
        "    validation_set=val_series_set,\n",
        "    n_forecasts=28,\n",
        "    past_covariates_train=train_exog_set,\n",
        "    past_covariates_validation=val_exog_set,\n",
        "    series_list=True,\n",
        "    model_name='LightGBM'\n",
        ")\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "EqaeNOXBmkS1",
        "outputId": "05890f46-daca-4e75-a188-5e1b5ddd7efd"
      },
      "execution_count": 72,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "-----------------------------------------\n",
            "MAE (LightGBM) = 0.12\n",
            "sMAPE (LightGBM) = 115.71\n",
            "RMSE (LightGBM) = 0.14\n",
            "Training Time (LightGBM) = 72.68sec\n",
            "Forecast Time (LightGBM) = 4.55sec\n",
            "Total Time (LightGBM) = 77.23sec\n",
            "-----------------------------------------\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# if smape is to be calculated manually\n",
        "'''\n",
        "predicted_series_set = results['forecast']\n",
        "rescaled_val_series_set = [Scale_series.inverse_transform(series) for series in val_series_set]\n",
        "rescaled_predicted_series_set = [Scale_series.inverse_transform(series) for series in predicted_series_set]\n",
        "\n",
        "smape(rescaled_val_series_set, rescaled_predicted_series_set, inter_reduction=np.mean)\n",
        "'''"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gIHG0YqA24pH",
        "outputId": "b85521f5-08ea-46f4-8de6-4eee5124edbd"
      },
      "execution_count": 75,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## **Results Comparision for different subsets of dataset**"
      ],
      "metadata": {
        "id": "Q2OOPTAQBqTw"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "metrics_df = add_metrics_to_df(\n",
        "    metrics_df,\n",
        "    store_id = store_id,\n",
        "    dept_id = dept_id,\n",
        "    model_name = 'LightGBM',\n",
        "    mae = results['MAE'],\n",
        "    smape = results['sMAPE'],\n",
        "    rmse = results['RMSE'],\n",
        "    training_time = results['Training Time'],\n",
        "    forecast_time = results['Forecast Time'],\n",
        "    total_time = results['Total Time'],\n",
        "    dataset_size = dataset_size\n",
        ")\n",
        "\n",
        "display(metrics_df)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 269
        },
        "id": "staDIKWX6lMG",
        "outputId": "42bbe7b4-91b4-4a28-fd13-261a94ceee87"
      },
      "execution_count": 74,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "  Store ID      Dept ID Model Name       MAE       sMAPE      RMSE  \\\n",
              "0     CA_1    HOBBIES_1   LightGBM  0.107672  148.803904  0.125280   \n",
              "0     CA_1    HOBBIES_2   LightGBM  0.044555  183.207458  0.061002   \n",
              "0     CA_1  HOUSEHOLD_1   LightGBM  0.118630  118.868008  0.140950   \n",
              "0     CA_1  HOUSEHOLD_2   LightGBM  0.172562  179.098179  0.242488   \n",
              "0     CA_1      FOODS_1   LightGBM  0.088543  125.784571  0.113485   \n",
              "0     CA_1      FOODS_2   LightGBM  0.101978  128.406439  0.117915   \n",
              "0     CA_1      FOODS_3   LightGBM  0.122019  115.705377  0.141701   \n",
              "\n",
              "   Training Time(seconds)  Forecast Time(seconds)  Total Time(seconds)  \\\n",
              "0               33.775537                5.871138            39.646674   \n",
              "0               10.212956                1.163260            11.376216   \n",
              "0               38.375891                3.119954            41.495845   \n",
              "0               38.158104                2.980633            41.138738   \n",
              "0               17.765503                1.661181            19.426684   \n",
              "0               38.375881                2.375662            40.751543   \n",
              "0               72.678828                4.547172            77.225999   \n",
              "\n",
              "   Dataset Size(MB)  \n",
              "0         67.065893  \n",
              "0         22.563300  \n",
              "0         81.064966  \n",
              "0         83.849216  \n",
              "0         35.845013  \n",
              "0         62.293983  \n",
              "0        129.412930  "
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-d1724c95-59d6-4b42-9d9a-4bcc515d0b01\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Store ID</th>\n",
              "      <th>Dept ID</th>\n",
              "      <th>Model Name</th>\n",
              "      <th>MAE</th>\n",
              "      <th>sMAPE</th>\n",
              "      <th>RMSE</th>\n",
              "      <th>Training Time(seconds)</th>\n",
              "      <th>Forecast Time(seconds)</th>\n",
              "      <th>Total Time(seconds)</th>\n",
              "      <th>Dataset Size(MB)</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>CA_1</td>\n",
              "      <td>HOBBIES_1</td>\n",
              "      <td>LightGBM</td>\n",
              "      <td>0.107672</td>\n",
              "      <td>148.803904</td>\n",
              "      <td>0.125280</td>\n",
              "      <td>33.775537</td>\n",
              "      <td>5.871138</td>\n",
              "      <td>39.646674</td>\n",
              "      <td>67.065893</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>CA_1</td>\n",
              "      <td>HOBBIES_2</td>\n",
              "      <td>LightGBM</td>\n",
              "      <td>0.044555</td>\n",
              "      <td>183.207458</td>\n",
              "      <td>0.061002</td>\n",
              "      <td>10.212956</td>\n",
              "      <td>1.163260</td>\n",
              "      <td>11.376216</td>\n",
              "      <td>22.563300</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>CA_1</td>\n",
              "      <td>HOUSEHOLD_1</td>\n",
              "      <td>LightGBM</td>\n",
              "      <td>0.118630</td>\n",
              "      <td>118.868008</td>\n",
              "      <td>0.140950</td>\n",
              "      <td>38.375891</td>\n",
              "      <td>3.119954</td>\n",
              "      <td>41.495845</td>\n",
              "      <td>81.064966</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>CA_1</td>\n",
              "      <td>HOUSEHOLD_2</td>\n",
              "      <td>LightGBM</td>\n",
              "      <td>0.172562</td>\n",
              "      <td>179.098179</td>\n",
              "      <td>0.242488</td>\n",
              "      <td>38.158104</td>\n",
              "      <td>2.980633</td>\n",
              "      <td>41.138738</td>\n",
              "      <td>83.849216</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>CA_1</td>\n",
              "      <td>FOODS_1</td>\n",
              "      <td>LightGBM</td>\n",
              "      <td>0.088543</td>\n",
              "      <td>125.784571</td>\n",
              "      <td>0.113485</td>\n",
              "      <td>17.765503</td>\n",
              "      <td>1.661181</td>\n",
              "      <td>19.426684</td>\n",
              "      <td>35.845013</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>CA_1</td>\n",
              "      <td>FOODS_2</td>\n",
              "      <td>LightGBM</td>\n",
              "      <td>0.101978</td>\n",
              "      <td>128.406439</td>\n",
              "      <td>0.117915</td>\n",
              "      <td>38.375881</td>\n",
              "      <td>2.375662</td>\n",
              "      <td>40.751543</td>\n",
              "      <td>62.293983</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>CA_1</td>\n",
              "      <td>FOODS_3</td>\n",
              "      <td>LightGBM</td>\n",
              "      <td>0.122019</td>\n",
              "      <td>115.705377</td>\n",
              "      <td>0.141701</td>\n",
              "      <td>72.678828</td>\n",
              "      <td>4.547172</td>\n",
              "      <td>77.225999</td>\n",
              "      <td>129.412930</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-d1724c95-59d6-4b42-9d9a-4bcc515d0b01')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-d1724c95-59d6-4b42-9d9a-4bcc515d0b01 button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-d1724c95-59d6-4b42-9d9a-4bcc515d0b01');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "<div id=\"df-e63034e3-82b8-4806-a548-eec31def38f6\">\n",
              "  <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-e63034e3-82b8-4806-a548-eec31def38f6')\"\n",
              "            title=\"Suggest charts\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "  </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "  <script>\n",
              "    async function quickchart(key) {\n",
              "      const quickchartButtonEl =\n",
              "        document.querySelector('#' + key + ' button');\n",
              "      quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "      quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "      try {\n",
              "        const charts = await google.colab.kernel.invokeFunction(\n",
              "            'suggestCharts', [key], {});\n",
              "      } catch (error) {\n",
              "        console.error('Error during call to suggestCharts:', error);\n",
              "      }\n",
              "      quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "      quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "    }\n",
              "    (() => {\n",
              "      let quickchartButtonEl =\n",
              "        document.querySelector('#df-e63034e3-82b8-4806-a548-eec31def38f6 button');\n",
              "      quickchartButtonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "    })();\n",
              "  </script>\n",
              "</div>\n",
              "    </div>\n",
              "  </div>\n"
            ]
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#**Cross Validation**"
      ],
      "metadata": {
        "id": "ugumS2cksd1f"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.model_selection._split import _BaseKFold, indexable, _num_samples\n",
        "from sklearn.utils.validation import _deprecate_positional_args\n",
        "#(n_splits=(default 5), max_train_size = (default = None))\n",
        "# https://github.com/getgaurav2/scikit-learn/blob/d4a3af5cc9da3a76f0266932644b884c99724c57/sklearn/model_selection/_split.py#L2243\n",
        "class GroupTimeSeriesSplit(_BaseKFold):\n",
        "    \"\"\"Time Series cross-validator variant with non-overlapping groups.\n",
        "    Provides train/test indices to split time series data samples\n",
        "    that are observed at fixed time intervals according to a\n",
        "    third-party provided group.\n",
        "    In each split, test indices must be higher than before, and thus shuffling\n",
        "    in cross validator is inappropriate.\n",
        "    This cross-validation object is a variation of :class:`KFold`.\n",
        "    In the kth split, it returns first k folds as train set and the\n",
        "    (k+1)th fold as test set.\n",
        "    The same group will not appear in two different folds (the number of\n",
        "    distinct groups has to be at least equal to the number of folds).\n",
        "    Note that unlike standard cross-validation methods, successive\n",
        "    training sets are supersets of those that come before them.\n",
        "    Read more in the :ref:`User Guide <cross_validation>`.\n",
        "    Parameters\n",
        "    ----------\n",
        "    n_splits : int, default=5\n",
        "        Number of splits. Must be at least 2.\n",
        "    max_train_size : int, default=None\n",
        "        Maximum size for a single training set.\n",
        "    Examples\n",
        "    --------\n",
        "    >>> import numpy as np\n",
        "    >>> from sklearn.model_selection import GroupTimeSeriesSplit\n",
        "    >>> groups = np.array(['a', 'a', 'a', 'a', 'a', 'a',\\\n",
        "                           'b', 'b', 'b', 'b', 'b',\\\n",
        "                           'c', 'c', 'c', 'c',\\\n",
        "                           'd', 'd', 'd'])\n",
        "    >>> gtss = GroupTimeSeriesSplit(n_splits=3)\n",
        "    >>> for train_idx, test_idx in gtss.split(groups, groups=groups):\n",
        "    ...     print(\"TRAIN:\", train_idx, \"TEST:\", test_idx)\n",
        "    ...     print(\"TRAIN GROUP:\", groups[train_idx],\\\n",
        "                  \"TEST GROUP:\", groups[test_idx])\n",
        "    TRAIN: [0, 1, 2, 3, 4, 5] TEST: [6, 7, 8, 9, 10]\n",
        "    TRAIN GROUP: ['a' 'a' 'a' 'a' 'a' 'a']\\\n",
        "    TEST GROUP: ['b' 'b' 'b' 'b' 'b']\n",
        "    TRAIN: [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10] TEST: [11, 12, 13, 14]\n",
        "    TRAIN GROUP: ['a' 'a' 'a' 'a' 'a' 'a' 'b' 'b' 'b' 'b' 'b']\\\n",
        "    TEST GROUP: ['c' 'c' 'c' 'c']\n",
        "    TRAIN: [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14]\\\n",
        "    TEST: [15, 16, 17]\n",
        "    TRAIN GROUP: ['a' 'a' 'a' 'a' 'a' 'a' 'b' 'b' 'b' 'b' 'b' 'c' 'c' 'c' 'c']\\\n",
        "    TEST GROUP: ['d' 'd' 'd']\n",
        "    \"\"\"\n",
        "    @_deprecate_positional_args\n",
        "    def __init__(self,\n",
        "                 n_splits=5,\n",
        "                 *,\n",
        "                 max_train_size=None\n",
        "                 ):\n",
        "        super().__init__(n_splits, shuffle=False, random_state=None)\n",
        "        self.max_train_size = max_train_size\n",
        "\n",
        "    def split(self, X, y=None, groups=None):\n",
        "        \"\"\"Generate indices to split data into training and test set.\n",
        "        Parameters\n",
        "        ----------\n",
        "        X : array-like of shape (n_samples, n_features)\n",
        "            Training data, where n_samples is the number of samples\n",
        "            and n_features is the number of features.\n",
        "        y : array-like of shape (n_samples,)\n",
        "            Always ignored, exists for compatibility.\n",
        "        groups : array-like of shape (n_samples,)\n",
        "            Group labels for the samples used while splitting the dataset into\n",
        "            train/test set.\n",
        "        Yields\n",
        "        ------\n",
        "        train : ndarray\n",
        "            The training set indices for that split.\n",
        "        test : ndarray\n",
        "            The testing set indices for that split.\n",
        "        \"\"\"\n",
        "        if groups is None:\n",
        "            raise ValueError(\n",
        "                \"The 'groups' parameter should not be None\")\n",
        "        X, y, groups = indexable(X, y, groups)\n",
        "        n_samples = _num_samples(X)\n",
        "        n_splits = self.n_splits\n",
        "        n_folds = n_splits + 1\n",
        "        group_dict = {}\n",
        "        u, ind = np.unique(groups, return_index=True)\n",
        "        unique_groups = u[np.argsort(ind)]\n",
        "        n_samples = _num_samples(X)\n",
        "        n_groups = _num_samples(unique_groups)\n",
        "        for idx in np.arange(n_samples):\n",
        "            if (groups[idx] in group_dict):\n",
        "                group_dict[groups[idx]].append(idx)\n",
        "            else:\n",
        "                group_dict[groups[idx]] = [idx]\n",
        "        if n_folds > n_groups:\n",
        "            raise ValueError(\n",
        "                (\"Cannot have number of folds={0} greater than\"\n",
        "                 \" the number of groups={1}\").format(n_folds,\n",
        "                                                     n_groups))\n",
        "        group_test_size = n_groups // n_folds\n",
        "        group_test_starts = range(n_groups - n_splits * group_test_size,\n",
        "                                  n_groups, group_test_size)\n",
        "        for group_test_start in group_test_starts:\n",
        "            train_array = []\n",
        "            test_array = []\n",
        "            for train_group_idx in unique_groups[:group_test_start]:\n",
        "                train_array_tmp = group_dict[train_group_idx]\n",
        "                train_array = np.sort(np.unique(\n",
        "                                      np.concatenate((train_array,\n",
        "                                                      train_array_tmp)),\n",
        "                                      axis=None), axis=None)\n",
        "            train_end = train_array.size\n",
        "            if self.max_train_size and self.max_train_size < train_end:\n",
        "                train_array = train_array[train_end -\n",
        "                                          self.max_train_size:train_end]\n",
        "            for test_group_idx in unique_groups[group_test_start:\n",
        "                                                group_test_start +\n",
        "                                                group_test_size]:\n",
        "                test_array_tmp = group_dict[test_group_idx]\n",
        "                test_array = np.sort(np.unique(\n",
        "                                              np.concatenate((test_array,\n",
        "                                                              test_array_tmp)),\n",
        "                                     axis=None), axis=None)\n",
        "            yield [int(i) for i in train_array], [int(i) for i in test_array]\n",
        "\n",
        "\n",
        "\n",
        "class PurgedGroupTimeSeriesSplit(_BaseKFold):\n",
        "    \"\"\"Time Series cross-validator variant with non-overlapping groups.\n",
        "    Allows for a gap in groups to avoid potentially leaking info from\n",
        "    train into test if the model has windowed or lag features.\n",
        "    Provides train/test indices to split time series data samples\n",
        "    that are observed at fixed time intervals according to a\n",
        "    third-party provided group.\n",
        "    In each split, test indices must be higher than before, and thus shuffling\n",
        "    in cross validator is inappropriate.\n",
        "    This cross-validation object is a variation of :class:`KFold`.\n",
        "    In the kth split, it returns first k folds as train set and the\n",
        "    (k+1)th fold as test set.\n",
        "    The same group will not appear in two different folds (the number of\n",
        "    distinct groups has to be at least equal to the number of folds).\n",
        "    Note that unlike standard cross-validation methods, successive\n",
        "    training sets are supersets of those that come before them.\n",
        "    Read more in the :ref:`User Guide <cross_validation>`.\n",
        "    Parameters\n",
        "    ----------\n",
        "    n_splits : int, default=5\n",
        "        Number of splits. Must be at least 2.\n",
        "    max_train_group_size : int, default=Inf\n",
        "        Maximum group size for a single training set.\n",
        "    group_gap : int, default=None\n",
        "        Gap between train and test\n",
        "    max_test_group_size : int, default=Inf\n",
        "        We discard this number of groups from the end of each train split\n",
        "    \"\"\"\n",
        "\n",
        "    @_deprecate_positional_args\n",
        "    def __init__(self,\n",
        "                 n_splits=5,\n",
        "                 *,\n",
        "                 max_train_group_size=np.inf,\n",
        "                 max_test_group_size=np.inf,\n",
        "                 group_gap=None,\n",
        "                 verbose=False\n",
        "                 ):\n",
        "        super().__init__(n_splits, shuffle=False, random_state=None)\n",
        "        self.max_train_group_size = max_train_group_size\n",
        "        self.group_gap = group_gap\n",
        "        self.max_test_group_size = max_test_group_size\n",
        "        self.verbose = verbose\n",
        "\n",
        "    def split(self, X, y=None, groups=None):\n",
        "        \"\"\"Generate indices to split data into training and test set.\n",
        "        Parameters\n",
        "        ----------\n",
        "        X : array-like of shape (n_samples, n_features)\n",
        "            Training data, where n_samples is the number of samples\n",
        "            and n_features is the number of features.\n",
        "        y : array-like of shape (n_samples,)\n",
        "            Always ignored, exists for compatibility.\n",
        "        groups : array-like of shape (n_samples,)\n",
        "            Group labels for the samples used while splitting the dataset into\n",
        "            train/test set.\n",
        "        Yields\n",
        "        ------\n",
        "        train : ndarray\n",
        "            The training set indices for that split.\n",
        "        test : ndarray\n",
        "            The testing set indices for that split.\n",
        "        \"\"\"\n",
        "        if groups is None:\n",
        "            raise ValueError(\n",
        "                \"The 'groups' parameter should not be None\")\n",
        "        X, y, groups = indexable(X, y, groups)\n",
        "        n_samples = _num_samples(X)\n",
        "        n_splits = self.n_splits\n",
        "        group_gap = self.group_gap\n",
        "        max_test_group_size = self.max_test_group_size\n",
        "        max_train_group_size = self.max_train_group_size\n",
        "        n_folds = n_splits + 1\n",
        "        group_dict = {}\n",
        "        u, ind = np.unique(groups, return_index=True)\n",
        "        unique_groups = u[np.argsort(ind)]\n",
        "        n_samples = _num_samples(X)\n",
        "        n_groups = _num_samples(unique_groups)\n",
        "        for idx in np.arange(n_samples):\n",
        "            if (groups[idx] in group_dict):\n",
        "                group_dict[groups[idx]].append(idx)\n",
        "            else:\n",
        "                group_dict[groups[idx]] = [idx]\n",
        "        if n_folds > n_groups:\n",
        "            raise ValueError(\n",
        "                (\"Cannot have number of folds={0} greater than\"\n",
        "                 \" the number of groups={1}\").format(n_folds,\n",
        "                                                     n_groups))\n",
        "\n",
        "        group_test_size = min(n_groups // n_folds, max_test_group_size)\n",
        "        group_test_starts = range(n_groups - n_splits * group_test_size,\n",
        "                                  n_groups, group_test_size)\n",
        "        for group_test_start in group_test_starts:\n",
        "            train_array = []\n",
        "            test_array = []\n",
        "\n",
        "            group_st = max(0, group_test_start - group_gap - max_train_group_size)\n",
        "            for train_group_idx in unique_groups[group_st:(group_test_start - group_gap)]:\n",
        "                train_array_tmp = group_dict[train_group_idx]\n",
        "\n",
        "                train_array = np.sort(np.unique(\n",
        "                                      np.concatenate((train_array,\n",
        "                                                      train_array_tmp)),\n",
        "                                      axis=None), axis=None)\n",
        "\n",
        "            train_end = train_array.size\n",
        "\n",
        "            for test_group_idx in unique_groups[group_test_start:\n",
        "                                                group_test_start +\n",
        "                                                group_test_size]:\n",
        "                test_array_tmp = group_dict[test_group_idx]\n",
        "                test_array = np.sort(np.unique(\n",
        "                                              np.concatenate((test_array,\n",
        "                                                              test_array_tmp)),\n",
        "                                     axis=None), axis=None)\n",
        "\n",
        "            test_array  = test_array[group_gap:]\n",
        "\n",
        "\n",
        "            if self.verbose > 0:\n",
        "                    pass\n",
        "\n",
        "            yield [int(i) for i in train_array], [int(i) for i in test_array]\n",
        "\n"
      ],
      "metadata": {
        "id": "Xj6-NtfwwMKP"
      },
      "execution_count": 33,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df_cv = formatted_df.copy()\n",
        "\n",
        "# Convert 'date' column to datetime\n",
        "df_cv['date'] = pd.to_datetime(df_cv['date'])\n",
        "\n",
        "# Create sub-group identifiers combining 'id' and the month\n",
        "df_cv['sub_group'] = df_cv['id'] + '_' + df_cv['date'].dt.to_period('M').astype(str)\n",
        "\n",
        "X = df_cv[['id', 'date', 'value']]  # Features including 'id' for grouping\n",
        "groups = df_cv['sub_group']         # Sub-group as the group labels\n"
      ],
      "metadata": {
        "id": "4XAmRvYWykTg"
      },
      "execution_count": 56,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## **Group Cross Validation**"
      ],
      "metadata": {
        "id": "yRxGb3oll7Rc"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "train_data_splits = []\n",
        "test_data_splits = []\n",
        "train_exog_splits = []\n",
        "test_exog_splits = []\n",
        "\n",
        "n_splits = 3\n",
        "\n",
        "exogenous_features = ['sell_price', 'snap_CA', 'snap_TX', 'snap_WI'] + \\\n",
        "    [e for e in df_cv.columns if e.startswith('event')] + \\\n",
        "    [e for e in df_cv.columns if e.startswith('event2')]\n",
        "\n",
        "\n",
        "# Performing cross-validation for each group with sub-groups\n",
        "gtss = GroupTimeSeriesSplit(n_splits=n_splits)\n",
        "\n",
        "unique_groups = df_cv['id'].unique()\n",
        "for group in unique_groups:\n",
        "\n",
        "    group_data = df_cv[df_cv['id'] == group].reset_index(drop=True)\n",
        "\n",
        "    X_group = group_data  # Group-specific feature\n",
        "    sub_groups = group_data['sub_group']     # Sub-groups\n",
        "\n",
        "    for train_idx, test_idx in gtss.split(X_group, groups=sub_groups):\n",
        "\n",
        "        test_exog_idx = extend_index_with_past(24,train_idx, test_idx, X_group)\n",
        "\n",
        "        X_train, X_test, X_test_exog = X_group.iloc[train_idx], X_group.iloc[test_idx],X_group.iloc[test_exog_idx]\n",
        "\n",
        "        X_train_ts, X_test_ts = TimeSeries.from_dataframe(X_train, time_col='date', value_cols='value'),TimeSeries.from_dataframe(X_test, time_col='date', value_cols='value')\n",
        "        exog_train_ts, exog_test_ts = TimeSeries.from_dataframe(X_train, time_col='date', value_cols=exogenous_features),TimeSeries.from_dataframe(X_test_exog, time_col='date', value_cols=exogenous_features)\n",
        "\n",
        "        train_data_splits.append(X_train_ts)\n",
        "        test_data_splits.append(X_test_ts)\n",
        "        train_exog_splits.append(exog_train_ts)\n",
        "        test_exog_splits.append(exog_test_ts)\n",
        "\n",
        "# Splitting the train and test data splits into lists, one for each split\n",
        "train_splits = [train_data_splits[i::n_splits] for i in range(n_splits)]\n",
        "test_splits = [test_data_splits[i::n_splits] for i in range(n_splits)]\n",
        "exog_train_splits = [train_exog_splits[i::n_splits] for i in range(n_splits)]\n",
        "exog_test_splits = [test_exog_splits[i::n_splits] for i in range(n_splits)]\n",
        "\n",
        "del train_data_splits, test_data_splits, train_exog_splits, test_exog_splits\n",
        "\n",
        "# LightGBM\n",
        "\n",
        "model_lgbm = create_lightgbm_model(lags_past_covariates = 2)\n",
        "\n",
        "for train_split, test_split, exog_train, exog_test in zip(train_splits, test_splits, exog_train_splits, exog_test_splits ):\n",
        "\n",
        "  results = fit_predict_and_evaluate(\n",
        "      model=model_lgbm,\n",
        "      training_set=train_split,\n",
        "      validation_set=test_split,\n",
        "      n_forecasts=28,\n",
        "      past_covariates_train=exog_train,\n",
        "      past_covariates_validation=exog_test,\n",
        "      series_list=True,\n",
        "      model_name='LightGBM'\n",
        "  )\n",
        "\n",
        "# Nbeats\n",
        "\n",
        "model = create_nbeats_model()\n",
        "\n",
        "for train_split, test_split, exog_train, exog_test in zip(train_splits, test_splits, exog_train_splits, exog_test_splits ):\n",
        "\n",
        "\n",
        "  results = fit_predict_and_evaluate(\n",
        "  model=model,\n",
        "  training_set=train_split,\n",
        "  validation_set=test_split,\n",
        "  n_forecasts=48,\n",
        "  past_covariates_train=exog_train,\n",
        "  past_covariates_validation=exog_test,\n",
        "  series_list=True,\n",
        "  model_name='Nbeats'\n",
        ")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000,
          "referenced_widgets": [
            "7b55fe52d1e942d4be145ee8e1367da9",
            "37b131706bac42c9b7f2e6a4cdd7f9b6",
            "209c70eb4f4e4bbbbf18b03648abc574",
            "30226d58f0ec42aa96612d5454526941",
            "cbc68432f9c64326a4c749478538b840",
            "6e732945e2b842d58b32dfae0abbcdbc",
            "732ff793d63a4d1c9b46ec9ed2a28381",
            "113e5f19448e46e7b58ccf0376e3d07c",
            "22d9e2141c3a492aae7d0e4c340b6963",
            "7534429c6c2e4147a557632e441bc88e",
            "1219386ea257466c93ae0c5223546416",
            "6cb1193514a24042a4fc2ecbe6d223c9",
            "d74e73c4515e4b46b8a501158ec36818",
            "c209fe163f1644e9afe1187b9e7a19a0",
            "cab1c977fcdb4a9e87d49cfbb5485e86",
            "e34164f4b0c5446092ca5ed80a3893b0",
            "2329d7e8a6bb471c91928a0689b91fa3",
            "8781e6ce1b2d4a0f82f805339f738335",
            "d24733f703b849578bc6227d3b5379c5",
            "c5798a95031d44b68e90cac2546a8cfb",
            "842e56cba83f4c0bb445bf5bb3832d92",
            "2cc8b99e0636416788cabcfc6cae551c"
          ]
        },
        "id": "JQajcDQQzFue",
        "outputId": "2ee4cbc7-5ff1-47d0-e21d-894bb1b89d4f"
      },
      "execution_count": 57,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "-----------------------------------------\n",
            "MAE (LightGBM) = 1.54\n",
            "sMAPE (LightGBM) = 128.75\n",
            "RMSE (LightGBM) = 1.98\n",
            "Training Time (LightGBM) = 1.20sec\n",
            "Forecast Time (LightGBM) = 1.37sec\n",
            "Total Time (LightGBM) = 2.57sec\n",
            "-----------------------------------------\n",
            "-----------------------------------------\n",
            "MAE (LightGBM) = 1.41\n",
            "sMAPE (LightGBM) = 133.14\n",
            "RMSE (LightGBM) = 1.81\n",
            "Training Time (LightGBM) = 1.67sec\n",
            "Forecast Time (LightGBM) = 0.96sec\n",
            "Total Time (LightGBM) = 2.63sec\n",
            "-----------------------------------------\n",
            "-----------------------------------------\n",
            "MAE (LightGBM) = 1.41\n",
            "sMAPE (LightGBM) = 126.35\n",
            "RMSE (LightGBM) = 1.86\n",
            "Training Time (LightGBM) = 2.33sec\n",
            "Forecast Time (LightGBM) = 0.93sec\n",
            "Total Time (LightGBM) = 3.26sec\n",
            "-----------------------------------------\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:pytorch_lightning.utilities.rank_zero:GPU available: False, used: False\n",
            "INFO:pytorch_lightning.utilities.rank_zero:TPU available: False, using: 0 TPU cores\n",
            "INFO:pytorch_lightning.utilities.rank_zero:IPU available: False, using: 0 IPUs\n",
            "INFO:pytorch_lightning.utilities.rank_zero:HPU available: False, using: 0 HPUs\n",
            "INFO:pytorch_lightning.callbacks.model_summary:\n",
            "  | Name          | Type             | Params\n",
            "---------------------------------------------------\n",
            "0 | criterion     | MSELoss          | 0     \n",
            "1 | train_metrics | MetricCollection | 0     \n",
            "2 | val_metrics   | MetricCollection | 0     \n",
            "3 | stacks        | ModuleList       | 250 K \n",
            "---------------------------------------------------\n",
            "244 K     Trainable params\n",
            "6.7 K     Non-trainable params\n",
            "250 K     Total params\n",
            "1.004     Total estimated model params size (MB)\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Training: |          | 0/? [00:00<?, ?it/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "7b55fe52d1e942d4be145ee8e1367da9"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/pytorch_lightning/trainer/call.py:54: Detected KeyboardInterrupt, attempting graceful shutdown...\n",
            "INFO:pytorch_lightning.utilities.rank_zero:GPU available: False, used: False\n",
            "INFO:pytorch_lightning.utilities.rank_zero:TPU available: False, using: 0 TPU cores\n",
            "INFO:pytorch_lightning.utilities.rank_zero:IPU available: False, using: 0 IPUs\n",
            "INFO:pytorch_lightning.utilities.rank_zero:HPU available: False, using: 0 HPUs\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Predicting: |          | 0/? [00:00<?, ?it/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "6cb1193514a24042a4fc2ecbe6d223c9"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-57-a2df8fcb4f23>\u001b[0m in \u001b[0;36m<cell line: 67>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     68\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     69\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 70\u001b[0;31m   results = fit_predict_and_evaluate(\n\u001b[0m\u001b[1;32m     71\u001b[0m   \u001b[0mmodel\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     72\u001b[0m   \u001b[0mtraining_set\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtrain_split\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-4-def7462d58ee>\u001b[0m in \u001b[0;36mfit_predict_and_evaluate\u001b[0;34m(model, training_set, validation_set, n_forecasts, past_covariates_train, past_covariates_validation, series_list, model_name)\u001b[0m\n\u001b[1;32m     40\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     41\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 42\u001b[0;31m     \u001b[0mmae_value\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmae\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvalidation_set\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mforecast\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minter_reduction\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmean\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     43\u001b[0m     \u001b[0msmape_value\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msmape\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvalidation_set\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mforecast\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minter_reduction\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmean\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     44\u001b[0m     \u001b[0mrmse_value\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mrmse\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvalidation_set\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mforecast\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minter_reduction\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmean\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/darts/metrics/metrics.py\u001b[0m in \u001b[0;36mwrapper_multi_ts_support\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     85\u001b[0m         )\n\u001b[1;32m     86\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 87\u001b[0;31m         value_list = _parallel_apply(\n\u001b[0m\u001b[1;32m     88\u001b[0m             \u001b[0miterator\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0miterator\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     89\u001b[0m             \u001b[0mfn\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mfunc\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/darts/utils/utils.py\u001b[0m in \u001b[0;36m_parallel_apply\u001b[0;34m(iterator, fn, n_jobs, fn_args, fn_kwargs)\u001b[0m\n\u001b[1;32m    207\u001b[0m     \"\"\"\n\u001b[1;32m    208\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 209\u001b[0;31m     returned_data = Parallel(n_jobs=n_jobs)(\n\u001b[0m\u001b[1;32m    210\u001b[0m         \u001b[0mdelayed\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfn\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0msample\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0mfn_args\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mfn_kwargs\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0msample\u001b[0m \u001b[0;32min\u001b[0m \u001b[0miterator\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    211\u001b[0m     )\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/joblib/parallel.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, iterable)\u001b[0m\n\u001b[1;32m   1861\u001b[0m             \u001b[0moutput\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_get_sequential_output\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0miterable\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1862\u001b[0m             \u001b[0mnext\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutput\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1863\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0moutput\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreturn_generator\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0mlist\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutput\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1864\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1865\u001b[0m         \u001b[0;31m# Let's create an ID that uniquely identifies the current call. If the\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/joblib/parallel.py\u001b[0m in \u001b[0;36m_get_sequential_output\u001b[0;34m(self, iterable)\u001b[0m\n\u001b[1;32m   1790\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mn_dispatched_batches\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1791\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mn_dispatched_tasks\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1792\u001b[0;31m                 \u001b[0mres\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1793\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mn_completed_tasks\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1794\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mprint_progress\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/darts/metrics/metrics.py\u001b[0m in \u001b[0;36mwrapper_multivariate_support\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    131\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mactual_series\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwidth\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    132\u001b[0m             value_list.append(\n\u001b[0;32m--> 133\u001b[0;31m                 func(\n\u001b[0m\u001b[1;32m    134\u001b[0m                     \u001b[0mactual_series\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0munivariate_component\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    135\u001b[0m                     \u001b[0mpred_series\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0munivariate_component\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/darts/metrics/metrics.py\u001b[0m in \u001b[0;36mmae\u001b[0;34m(actual_series, pred_series, intersect, reduction, inter_reduction, n_jobs, verbose)\u001b[0m\n\u001b[1;32m    284\u001b[0m     \"\"\"\n\u001b[1;32m    285\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 286\u001b[0;31m     y1, y2 = _get_values_or_raise(\n\u001b[0m\u001b[1;32m    287\u001b[0m         \u001b[0mactual_series\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpred_series\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mintersect\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mremove_nan_union\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    288\u001b[0m     )\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/darts/metrics/metrics.py\u001b[0m in \u001b[0;36m_get_values_or_raise\u001b[0;34m(series_a, series_b, intersect, stochastic_quantile, remove_nan_union)\u001b[0m\n\u001b[1;32m    203\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    204\u001b[0m     \u001b[0mseries_a_common\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mseries_a\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mslice_intersect\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mseries_b\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mintersect\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0mseries_a\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 205\u001b[0;31m     \u001b[0mseries_b_common\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mseries_b\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mslice_intersect\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mseries_a\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mintersect\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0mseries_b\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    206\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    207\u001b[0m     raise_if_not(\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/darts/timeseries.py\u001b[0m in \u001b[0;36mslice_intersect\u001b[0;34m(self, other)\u001b[0m\n\u001b[1;32m   2405\u001b[0m         \"\"\"\n\u001b[1;32m   2406\u001b[0m         \u001b[0mtime_index\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtime_index\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mintersection\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mother\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtime_index\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2407\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mtime_index\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2408\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2409\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mstrip\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhow\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mstr\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m\"all\"\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0mSelf\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/darts/timeseries.py\u001b[0m in \u001b[0;36m__getitem__\u001b[0;34m(self, key)\u001b[0m\n\u001b[1;32m   4922\u001b[0m             \u001b[0;31m# indexing may discard the freq so we restore it...\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   4923\u001b[0m             \u001b[0;31m# TODO: unit-test this\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 4924\u001b[0;31m             \u001b[0m_set_freq_in_xa\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mxa_\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   4925\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   4926\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__class__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mxa_\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/darts/timeseries.py\u001b[0m in \u001b[0;36m_set_freq_in_xa\u001b[0;34m(xa_)\u001b[0m\n\u001b[1;32m   4905\u001b[0m                 \u001b[0minferred_freq\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mxa_\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_index\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_time_dim\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minferred_freq\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   4906\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0minferred_freq\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 4907\u001b[0;31m                     \u001b[0mxa_\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_index\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_time_dim\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfreq\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mto_offset\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minferred_freq\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   4908\u001b[0m                 \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   4909\u001b[0m                     \u001b[0mxa_\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_index\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_time_dim\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfreq\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_freq\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/pandas/_libs/tslibs/offsets.pyx\u001b[0m in \u001b[0;36mpandas._libs.tslibs.offsets.to_offset\u001b[0;34m()\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/pandas/_libs/tslibs/offsets.pyx\u001b[0m in \u001b[0;36mpandas._libs.tslibs.offsets.to_offset\u001b[0;34m()\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/pandas/_libs/tslibs/offsets.pyx\u001b[0m in \u001b[0;36mpandas._libs.tslibs.offsets.Tick.__mul__\u001b[0;34m()\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/numpy/core/overrides.py\u001b[0m in \u001b[0;36misclose\u001b[0;34m(*args, **kwargs)\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/numpy/core/numeric.py\u001b[0m in \u001b[0;36misclose\u001b[0;34m(a, b, rtol, atol, equal_nan)\u001b[0m\n\u001b[1;32m   2373\u001b[0m     \u001b[0myfin\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0misfinite\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2374\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mall\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mxfin\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mall\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0myfin\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2375\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mwithin_tol\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0matol\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrtol\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2376\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2377\u001b[0m         \u001b[0mfinite\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mxfin\u001b[0m \u001b[0;34m&\u001b[0m \u001b[0myfin\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/numpy/core/numeric.py\u001b[0m in \u001b[0;36mwithin_tol\u001b[0;34m(x, y, atol, rtol)\u001b[0m\n\u001b[1;32m   2353\u001b[0m     \"\"\"\n\u001b[1;32m   2354\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mwithin_tol\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0matol\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrtol\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2355\u001b[0;31m         \u001b[0;32mwith\u001b[0m \u001b[0merrstate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minvalid\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'ignore'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2356\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mless_equal\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mabs\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0my\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0matol\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mrtol\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0mabs\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2357\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/numpy/core/_ufunc_config.py\u001b[0m in \u001b[0;36m__enter__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    427\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mkwargs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    428\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 429\u001b[0;31m     \u001b[0;32mdef\u001b[0m \u001b[0m__enter__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    430\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moldstate\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mseterr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m**\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    431\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcall\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0m_Unspecified\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## **Purged group cross validation**"
      ],
      "metadata": {
        "id": "MiEvXGYqlxRH"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "train_data_splits = []\n",
        "test_data_splits = []\n",
        "train_exog_splits = []\n",
        "test_exog_splits = []\n",
        "\n",
        "n_splits = 3\n",
        "\n",
        "exogenous_features = ['sell_price', 'snap_CA', 'snap_TX', 'snap_WI'] + \\\n",
        "    [e for e in df_cv.columns if e.startswith('event')] + \\\n",
        "    [e for e in df_cv.columns if e.startswith('event2')]\n",
        "\n",
        "\n",
        "# Performing cross-validation for each group with sub-groups\n",
        "pgtss = PurgedGroupTimeSeriesSplit(n_splits=n_splits, group_gap=1,max_train_group_size=15,max_test_group_size=5)\n",
        "\n",
        "unique_groups = df_cv['id'].unique()\n",
        "for group in unique_groups:\n",
        "\n",
        "    group_data = df_cv[df_cv['id'] == group].reset_index(drop=True)\n",
        "\n",
        "    X_group = group_data  # Group-specific feature\n",
        "    sub_groups = group_data['sub_group']     # Sub-groups\n",
        "\n",
        "    for train_idx, test_idx in pgtss.split(X_group, groups=sub_groups):\n",
        "\n",
        "        test_exog_idx = extend_index_with_past(24, train_idx, test_idx, X_group)\n",
        "\n",
        "        X_train, X_test, X_test_exog = X_group.iloc[train_idx], X_group.iloc[test_idx],X_group.iloc[test_exog_idx]\n",
        "\n",
        "        X_train_ts, X_test_ts = TimeSeries.from_dataframe(X_train, time_col='date', value_cols='value'),TimeSeries.from_dataframe(X_test, time_col='date', value_cols='value')\n",
        "        exog_train_ts, exog_test_ts = TimeSeries.from_dataframe(X_train, time_col='date', value_cols=exogenous_features),TimeSeries.from_dataframe(X_test_exog, time_col='date', value_cols=exogenous_features)\n",
        "\n",
        "        train_data_splits.append(X_train_ts)\n",
        "        test_data_splits.append(X_test_ts)\n",
        "        train_exog_splits.append(exog_train_ts)\n",
        "        test_exog_splits.append(exog_test_ts)\n",
        "\n",
        "# Splitting the train and test data splits into lists, one for each split\n",
        "train_splits = [train_data_splits[i::n_splits] for i in range(n_splits)]\n",
        "test_splits = [test_data_splits[i::n_splits] for i in range(n_splits)]\n",
        "exog_train_splits = [train_exog_splits[i::n_splits] for i in range(n_splits)]\n",
        "exog_test_splits = [test_exog_splits[i::n_splits] for i in range(n_splits)]\n",
        "\n",
        "del train_data_splits, test_data_splits,  train_exog_splits, test_exog_splits\n",
        "\n",
        "# LightGBM\n",
        "\n",
        "model_lgbm = create_lightgbm_model(lags_past_covariates = 2)\n",
        "\n",
        "for train_split, test_split, exog_train, exog_test in zip(train_splits, test_splits, exog_train_splits, exog_test_splits ):\n",
        "\n",
        "  results = fit_predict_and_evaluate(\n",
        "      model=model_lgbm,\n",
        "      training_set=train_split,\n",
        "      validation_set=test_split,\n",
        "      n_forecasts=35,\n",
        "      past_covariates_train=exog_train,\n",
        "      past_covariates_validation=exog_test,\n",
        "      series_list=True,\n",
        "      model_name='LightGBM'\n",
        "  )\n",
        "\n",
        "# Nbeats\n",
        "\n",
        "model = create_nbeats_model()\n",
        "\n",
        "for train_split, test_split, exog_train, exog_test in zip(train_splits, test_splits, exog_train_splits, exog_test_splits ):\n",
        "\n",
        "\n",
        "  results = fit_predict_and_evaluate(\n",
        "  model=model,\n",
        "  training_set=train_split,\n",
        "  validation_set=test_split,\n",
        "  n_forecasts=48,\n",
        "  past_covariates_train=exog_train,\n",
        "  past_covariates_validation=exog_test,\n",
        "  series_list=True,\n",
        "  model_name='Nbeats'\n",
        ")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 504
        },
        "id": "b3TJq3-nd_9e",
        "outputId": "77b8d9c9-078d-46ab-86f3-250314b3c3ef"
      },
      "execution_count": 58,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "-----------------------------------------\n",
            "MAE (LightGBM) = 1.53\n",
            "sMAPE (LightGBM) = 132.09\n",
            "RMSE (LightGBM) = 1.81\n",
            "Training Time (LightGBM) = 0.92sec\n",
            "Forecast Time (LightGBM) = 0.96sec\n",
            "Total Time (LightGBM) = 1.88sec\n",
            "-----------------------------------------\n",
            "-----------------------------------------\n",
            "MAE (LightGBM) = 1.42\n",
            "sMAPE (LightGBM) = 128.09\n",
            "RMSE (LightGBM) = 1.62\n",
            "Training Time (LightGBM) = 0.93sec\n",
            "Forecast Time (LightGBM) = 0.93sec\n",
            "Total Time (LightGBM) = 1.85sec\n",
            "-----------------------------------------\n",
            "-----------------------------------------\n",
            "MAE (LightGBM) = 1.32\n",
            "sMAPE (LightGBM) = 139.26\n",
            "RMSE (LightGBM) = 1.48\n",
            "Training Time (LightGBM) = 1.33sec\n",
            "Forecast Time (LightGBM) = 1.28sec\n",
            "Total Time (LightGBM) = 2.61sec\n",
            "-----------------------------------------\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "\"\\nmodel = create_nbeats_model()\\n\\nfor train_split, test_split, exog_train, exog_test in zip(train_splits, test_splits, exog_train_splits, exog_test_splits ):\\n\\n\\n  results = fit_predict_and_evaluate(\\n  model=model,\\n  training_set=train_split,\\n  validation_set=test_split,\\n  n_forecasts=48,\\n  past_covariates_train=exog_train,\\n  past_covariates_validation=exog_test,\\n  series_list=True,\\n  model_name='Nbeats'\\n)\\n\""
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 58
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#**Optuna Hyper parameter optimization**"
      ],
      "metadata": {
        "id": "bB9Tbjpi30gL"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def objective(trial, training_data, validation_data, model_type, past_cov_train, past_cov_validation,model_name):\n",
        "    \"\"\"\n",
        "    Optuna objective function for hyperparameter optimization.\n",
        "    This function is to find the best parameters for a model\n",
        "    to minimize the Symmetric Mean Absolute Percentage Error (sMAPE)\n",
        "    between predicted and actual values in a validation dataset.\n",
        "    \"\"\"\n",
        "    # Define hyperparameters\n",
        "\n",
        "\n",
        "    n_epochs = trial.suggest_int('n_epochs', 1, 10)\n",
        "    batch_size = trial.suggest_categorical('batch_size', [8, 16])\n",
        "\n",
        "    # Additional hyperparameters for specific models\n",
        "    if model_type == 'NBEATS':\n",
        "        output_chunk_length = trial.suggest_categorical('output_chunk_length', [24, 48])\n",
        "        num_stacks = trial.suggest_int('num_stacks', 1, 3)\n",
        "        num_blocks = trial.suggest_int('num_blocks', 1, 3)\n",
        "        num_layers = trial.suggest_int('num_layers', 1, 3)\n",
        "        layer_widths = trial.suggest_categorical('layer_widths', [16, 32, 64])\n",
        "        input_chunk_length = trial.suggest_categorical('input_chunk_length', [24, 48])\n",
        "        dropout = trial.suggest_float('dropout', 0.0, 0.2)\n",
        "        activation = trial.suggest_categorical('activation', ['ReLU', 'RReLU', 'LeakyReLU'])\n",
        "        model = create_nbeats_model(\n",
        "            input_chunk_length=input_chunk_length,\n",
        "            output_chunk_length=output_chunk_length,\n",
        "            generic_architecture=True,\n",
        "            num_stacks=num_stacks,\n",
        "            num_blocks=num_blocks,\n",
        "            num_layers=num_layers,\n",
        "            layer_widths=layer_widths,\n",
        "            n_epochs=n_epochs,\n",
        "            nr_epochs_val_period=1,\n",
        "            batch_size=batch_size,\n",
        "            model_name=\"NBEATS\"\n",
        "        )\n",
        "    elif model_type == 'LightGBM':\n",
        "        #output_chunk_length = trial.suggest_int('output_chunk_length', 1,24)\n",
        "        output_chunk_length = trial.suggest_int('output_chunk_length', 1,10)\n",
        "        lags_past_covariates = trial.suggest_int('lags_past_covariates', 1, 24)\n",
        "        lags = trial.suggest_int('lags', 1, 24)\n",
        "        max_depth = trial.suggest_int('max_depth', 2, 10)\n",
        "        n_estimators = trial.suggest_int('n_estimators', 10, 100)\n",
        "        learning_rate = trial.suggest_float('learning_rate', 0.01, 0.3)\n",
        "        num_leaves = trial.suggest_int('num_leaves', 20, 60)\n",
        "        extra_trees = trial.suggest_categorical('extra_trees', [True, False])\n",
        "\n",
        "        model = create_lightgbm_model(\n",
        "            lags_past_covariates=lags_past_covariates,\n",
        "            output_chunk_length=output_chunk_length,\n",
        "            lags=lags,\n",
        "            max_depth=max_depth,\n",
        "            n_estimators=n_estimators,\n",
        "            learning_rate=learning_rate,\n",
        "            verbose=-1,\n",
        "            num_leaves=num_leaves,\n",
        "            extra_trees=extra_trees\n",
        "        )\n",
        "    else:\n",
        "        raise ValueError(\"Invalid model type\")\n",
        "\n",
        "    # Predict and calculate sMAPE\n",
        "    forecast = fit_predict_and_evaluate(\n",
        "        model=model,\n",
        "        training_set=training_data,\n",
        "        validation_set=validation_data,\n",
        "        n_forecasts=28,\n",
        "        past_covariates_train=past_cov_train,\n",
        "        past_covariates_validation=past_cov_validation,\n",
        "        series_list=True,\n",
        "        model_name = model_name\n",
        "    )\n",
        "    smape_result = forecast['sMAPE']\n",
        "    mae_result = forecast['MAE']\n",
        "    rmse_result = forecast['RMSE']\n",
        "    combined_metric = 0.2 * mae_result + 0.6 * smape_result + 0.2 * rmse_result\n",
        "\n",
        "    return combined_metric"
      ],
      "metadata": {
        "id": "gpyptQhExu_8"
      },
      "execution_count": 87,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "study_LGBM = optuna.create_study(direction='minimize')\n",
        "study_LGBM.optimize(lambda trial: objective(trial, training_data = train_series_set, validation_data = val_series_set, past_cov_train= train_exog_set, past_cov_validation = val_exog_set ,model_name = 'LightGBM',model_type = 'LightGBM'), n_trials=10)\n",
        "\n",
        "print('Best Params for LightGBM:')\n",
        "trial_LGBM = study_LGBM.best_trial\n",
        "print(trial_LGBM.params)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 279
        },
        "id": "Hg3iF094JakF",
        "outputId": "d2273a50-a786-4bdd-ca1e-d08fe47c080d"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "error",
          "ename": "NameError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-2-668999057ce7>\u001b[0m in \u001b[0;36m<cell line: 1>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mstudy_LGBM\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0moptuna\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcreate_study\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdirection\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'minimize'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0mstudy_LGBM\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moptimize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;32mlambda\u001b[0m \u001b[0mtrial\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mobjective\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrial\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtraining_data\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtrain_series_set\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalidation_data\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mval_series_set\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpast_cov_train\u001b[0m\u001b[0;34m=\u001b[0m \u001b[0mtrain_exog_set\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpast_cov_validation\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mval_exog_set\u001b[0m \u001b[0;34m,\u001b[0m\u001b[0mmodel_name\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m'LightGBM'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mmodel_type\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m'LightGBM'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mn_trials\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m10\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'Best Params for LightGBM:'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0mtrial_LGBM\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mstudy_LGBM\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbest_trial\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mNameError\u001b[0m: name 'optuna' is not defined"
          ]
        }
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": [],
      "collapsed_sections": [
        "kmLNuH5nktTT",
        "wy6u-FWr_iGC",
        "NikcZTp9ARaC",
        "y2cumUb3DWhS",
        "yn4m6NZYvEW8",
        "uiAQxrjZsS-1",
        "jMSBcPEwsOMl",
        "Vi5aotRisKWZ",
        "0I4q4rJfsZ3o",
        "ugumS2cksd1f",
        "yRxGb3oll7Rc",
        "MiEvXGYqlxRH"
      ]
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "7b55fe52d1e942d4be145ee8e1367da9": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_37b131706bac42c9b7f2e6a4cdd7f9b6",
              "IPY_MODEL_209c70eb4f4e4bbbbf18b03648abc574",
              "IPY_MODEL_30226d58f0ec42aa96612d5454526941"
            ],
            "layout": "IPY_MODEL_cbc68432f9c64326a4c749478538b840"
          }
        },
        "37b131706bac42c9b7f2e6a4cdd7f9b6": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_6e732945e2b842d58b32dfae0abbcdbc",
            "placeholder": "​",
            "style": "IPY_MODEL_732ff793d63a4d1c9b46ec9ed2a28381",
            "value": "Epoch 1:  38%"
          }
        },
        "209c70eb4f4e4bbbbf18b03648abc574": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_113e5f19448e46e7b58ccf0376e3d07c",
            "max": 3369,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_22d9e2141c3a492aae7d0e4c340b6963",
            "value": 1294
          }
        },
        "30226d58f0ec42aa96612d5454526941": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_7534429c6c2e4147a557632e441bc88e",
            "placeholder": "​",
            "style": "IPY_MODEL_1219386ea257466c93ae0c5223546416",
            "value": " 1294/3369 [00:53&lt;01:25, 24.23it/s, train_loss=11.20]"
          }
        },
        "cbc68432f9c64326a4c749478538b840": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": "inline-flex",
            "flex": null,
            "flex_flow": "row wrap",
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": "100%"
          }
        },
        "6e732945e2b842d58b32dfae0abbcdbc": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "732ff793d63a4d1c9b46ec9ed2a28381": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "113e5f19448e46e7b58ccf0376e3d07c": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": "2",
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "22d9e2141c3a492aae7d0e4c340b6963": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "7534429c6c2e4147a557632e441bc88e": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "1219386ea257466c93ae0c5223546416": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "6cb1193514a24042a4fc2ecbe6d223c9": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_d74e73c4515e4b46b8a501158ec36818",
              "IPY_MODEL_c209fe163f1644e9afe1187b9e7a19a0",
              "IPY_MODEL_cab1c977fcdb4a9e87d49cfbb5485e86"
            ],
            "layout": "IPY_MODEL_e34164f4b0c5446092ca5ed80a3893b0"
          }
        },
        "d74e73c4515e4b46b8a501158ec36818": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_2329d7e8a6bb471c91928a0689b91fa3",
            "placeholder": "​",
            "style": "IPY_MODEL_8781e6ce1b2d4a0f82f805339f738335",
            "value": "Predicting DataLoader 0: 100%"
          }
        },
        "c209fe163f1644e9afe1187b9e7a19a0": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_d24733f703b849578bc6227d3b5379c5",
            "max": 7,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_c5798a95031d44b68e90cac2546a8cfb",
            "value": 7
          }
        },
        "cab1c977fcdb4a9e87d49cfbb5485e86": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_842e56cba83f4c0bb445bf5bb3832d92",
            "placeholder": "​",
            "style": "IPY_MODEL_2cc8b99e0636416788cabcfc6cae551c",
            "value": " 7/7 [00:00&lt;00:00,  9.52it/s]"
          }
        },
        "e34164f4b0c5446092ca5ed80a3893b0": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": "inline-flex",
            "flex": null,
            "flex_flow": "row wrap",
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": "100%"
          }
        },
        "2329d7e8a6bb471c91928a0689b91fa3": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "8781e6ce1b2d4a0f82f805339f738335": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "d24733f703b849578bc6227d3b5379c5": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": "2",
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "c5798a95031d44b68e90cac2546a8cfb": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "842e56cba83f4c0bb445bf5bb3832d92": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "2cc8b99e0636416788cabcfc6cae551c": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        }
      }
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}